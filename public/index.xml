<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The Code Forest</title>
    <link>http://example.org/</link>
      <atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml" />
    <description>The Code Forest</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Mark LeBoeuf</copyright><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>http://example.org/media/icon_huc737709a4be44af6221d1cabfe197959_22580_512x512_fill_lanczos_center_2.png</url>
      <title>The Code Forest</title>
      <link>http://example.org/</link>
    </image>
    
    <item>
      <title>Python basics</title>
      <link>http://example.org/courses/example/python/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://example.org/courses/example/python/</guid>
      <description>&lt;p&gt;Build a foundation in Python.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/rfscVS0vtbw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the difference between lists and tuples?&lt;/summary&gt;
  &lt;p&gt;&lt;p&gt;Lists&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lists are mutable - they can be changed&lt;/li&gt;
&lt;li&gt;Slower than tuples&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_list = [1, 2.0, &#39;Hello world&#39;]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tuples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tuples are immutable - they can&amp;rsquo;t be changed&lt;/li&gt;
&lt;li&gt;Tuples are faster than lists&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_tuple = (1, 2.0, &#39;Hello world&#39;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Is Python case-sensitive?&lt;/summary&gt;
  &lt;p&gt;Yes&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Visualization</title>
      <link>http://example.org/courses/example/visualization/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://example.org/courses/example/visualization/</guid>
      <description>&lt;p&gt;Learn how to visualize data with Plotly.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/hSPmj7mK6ng&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;When is a heatmap useful?&lt;/summary&gt;
  &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Write Plotly code to render a bar chart&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import plotly.express as px
data_canada = px.data.gapminder().query(&amp;quot;country == &#39;Canada&#39;&amp;quot;)
fig = px.bar(data_canada, x=&#39;year&#39;, y=&#39;pop&#39;)
fig.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Statistics</title>
      <link>http://example.org/courses/example/stats/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://example.org/courses/example/stats/</guid>
      <description>&lt;p&gt;Introduction to statistics for data science.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;p&gt;The general form of the &lt;strong&gt;normal&lt;/strong&gt; probability density function is:&lt;/p&gt;
&lt;p&gt;$$
f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the parameter $\mu$?&lt;/summary&gt;
  &lt;p&gt;The parameter $\mu$ is the mean or expectation of the distribution.&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>http://example.org/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>http://example.org/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scalable Time-Series Forecasting in Python</title>
      <link>http://example.org/post/2021-03-28-pyspark-forecasting/pyspark_time_series_forecasting/</link>
      <pubDate>Mon, 29 Mar 2021 21:13:14 -0500</pubDate>
      <guid>http://example.org/post/2021-03-28-pyspark-forecasting/pyspark_time_series_forecasting/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-03-28-pyspark-forecasting/images/header_image.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;p&gt;Whether predicting daily demand for thousands of products or the number of workers to staff across many distribution centers, generating operational forecasts in parallel is a common task for data scientists. Accordingly, the goal of this post is to outline an approach for creating many forecasts via PySpark. We’ll cover some common data-cleaning steps that often precede forecasting, and then generate several thousand week-level demand predictions for a variety consumer products. Note that we will not cover how to implement this workflow in a cloud computing environment (which, in a real-world setting, would typically be the case). Nor will we delve into model tuning or selection. The goal is to provide a straightforward workflow for quickly generating many time-series forecasts in parallel.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-started&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting Started&lt;/h3&gt;
&lt;p&gt;We’ll use data originally provided by Walmart that represents weekly demand for products at the store-department level. All code for this post is stored in the &lt;a href=&#34;https://github.com/thecodeforest/codeforest2.0/tree/main/content/post/2021-03-28-pyspark-forecasting/pyspark_fcast&#34;&gt;Codeforest Repository&lt;/a&gt;. Before diving into the details, let’s briefly review the key modules and files.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-03-28-pyspark-forecasting/images/project_tree.png&#34; width=&#34;300&#34; height=&#34;75&#34; /&gt;
&lt;strong&gt;conf.json&lt;/strong&gt; - A configuration file that defines various parameters for our job. It’s a good practice to keep these parameters outside of your actual code, as it makes it easier for others (or future you!) to adapt and extend to other use cases.
&lt;img src=&#34;http://example.org/post/2021-03-28-pyspark-forecasting/images/config_file.png&#34; width=&#34;700&#34; height=&#34;400&#34; /&gt;
&lt;strong&gt;pyspark_fcast.py&lt;/strong&gt; - Our main module, or where the forecasting gets done. We’ll cover this in detail below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;fcast_data_frame.py&lt;/strong&gt; - A class responsible for common pre-forecasting data transformations. These include filling in missing values, filtering time-series with only a few observations, or log transforming our outcome variable. Visit &lt;a href=&#34;https://github.com/thecodeforest/codeforest2.0/blob/main/content/post/2021-03-28-pyspark-forecasting/pyspark_fcast/fcast_helpers/fcast_data_frame.py&#34;&gt;here&lt;/a&gt; for access to all methods.&lt;/p&gt;
&lt;p&gt;You’ll also need to import the following packages to follow along with the tutorial.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import argparse
import json
import logging
import os
import re
from datetime import datetime
from pathlib import Path
from typing import List

import numpy as np
import pandas as pd

from fbprophet import Prophet # fbprophet==0.7.1 &amp;amp; pystan==2.18.0
from pyspark.sql import SparkSession # pyspark==3.0.1
from pyspark.sql.functions import lit
from pyspark.sql.types import (DateType, FloatType, IntegerType, StructField,
                               StructType)
                               
from pyspark_ts_fcast.fcast_data_frame import FcastDataFrame&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Assuming the imports were successful, we’ll peak at a few rows in our data to get a feel for the format.
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#rqobitfmng .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#rqobitfmng .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rqobitfmng .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#rqobitfmng .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#rqobitfmng .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rqobitfmng .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rqobitfmng .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#rqobitfmng .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#rqobitfmng .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#rqobitfmng .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#rqobitfmng .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#rqobitfmng .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#rqobitfmng .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#rqobitfmng .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#rqobitfmng .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#rqobitfmng .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#rqobitfmng .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#rqobitfmng .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rqobitfmng .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#rqobitfmng .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rqobitfmng .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#rqobitfmng .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#rqobitfmng .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rqobitfmng .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rqobitfmng .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#rqobitfmng .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rqobitfmng .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#rqobitfmng .gt_left {
  text-align: left;
}

#rqobitfmng .gt_center {
  text-align: center;
}

#rqobitfmng .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#rqobitfmng .gt_font_normal {
  font-weight: normal;
}

#rqobitfmng .gt_font_bold {
  font-weight: bold;
}

#rqobitfmng .gt_font_italic {
  font-style: italic;
}

#rqobitfmng .gt_super {
  font-size: 65%;
}

#rqobitfmng .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;rqobitfmng&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34; style=&#34;table-layout: fixed;; width: 0px&#34;&gt;
  &lt;colgroup&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
  &lt;/colgroup&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;4&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;strong&gt;Sample Data&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;4&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;store&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;dept&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;date&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly_sales&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-05&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;24924&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-12&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;46039&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-19&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;41596&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-26&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;19404&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-03-05&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;21828&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
Let’s now discuss the process of passing and documenting the forecasting parameters. We’ll execute the following from the command line to generate our forecasts:&lt;br /&gt;
&lt;code&gt;python3 pyspark_fcast.py --forecast-config-file &#39;config/conf.json&#39;&lt;/code&gt;&lt;br /&gt;
Here we are passing in the location of our configuration file and extracting the parameters. Don’t worry if the individual parameters don’t make sense now. I’ll explain each in greater detail below.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;args = read_args()

with open(args.forecast_config_file) as f:
    config = json.load(f)

log_input_params(config=config)

# forecasting parameters
input_data_path = config[&amp;quot;input_data_path&amp;quot;]
fcast_params = config[&amp;quot;fcast_parameters&amp;quot;]
group_fields = fcast_params[&amp;quot;group_fields&amp;quot;]
date_field = fcast_params[&amp;quot;date_field&amp;quot;]
yvar_field = fcast_params[&amp;quot;yvar_field&amp;quot;]
ts_frequency = fcast_params[&amp;quot;ts_frequency&amp;quot;]
fcast_floor = fcast_params[&amp;quot;forecast_floor&amp;quot;]
fcast_cap = fcast_params[&amp;quot;forecast_cap&amp;quot;]
min_obs_threshold = fcast_params[&amp;#39;min_obs_count&amp;#39;]

# spark parameters
spark_n_threads = str(config[&amp;#39;spark_n_threads&amp;#39;])
java_home = config[&amp;quot;java_home&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the two helper functions: &lt;em&gt;read_args&lt;/em&gt; and &lt;em&gt;log_input_params&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def read_args() -&amp;gt; argparse.Namespace:
    &amp;quot;&amp;quot;&amp;quot;Read Forecasting arguments 

    Returns:
        argparse.Namespace: argparse Namespace
    &amp;quot;&amp;quot;&amp;quot;
    parser = argparse.ArgumentParser()
    parser.add_argument(&amp;quot;--forecast-config-file&amp;quot;, type=str)
    return parser.parse_args()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;read_args&lt;/em&gt; takes arguments in our configuration file, then we document which parameters we’re using with &lt;em&gt;log_input_params&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;logging.basicConfig(
    format=&amp;quot;%(levelname)s - %(asctime)s - %(filename)s - %(message)s&amp;quot;,
    level=logging.INFO,
    filename=&amp;quot;run_{start_time}.log&amp;quot;.format(
        start_time=datetime.now().strftime(&amp;quot;%Y-%m-%d %H-%M-%S&amp;quot;)
    ),
)

def log_input_params(config: dict) -&amp;gt; None:
    &amp;quot;&amp;quot;&amp;quot;Logs all parameters in configuration file

    Args:
        config (dict): Configuration parameters for forecast and data
    &amp;quot;&amp;quot;&amp;quot;
    params = pd.json_normalize(config).transpose()
    [
        logging.info(&amp;quot;input params:&amp;quot; + x[0] + &amp;quot;-&amp;quot; + str(x[1]))
        for x in zip(params.index, params.iloc[:, 0])
    ]
    return None&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are several benefits to documenting our inputs. First, we can validate if the correct parameters have been passed to our forecasting process. Having a record of these values facilitates debugging. Second, it is useful for experimentation. We can try out different parameters to see which combination provides the best results. Logging does not receive a lot of attention in the data science world, but it is incredibly useful and will save you time as your project matures.&lt;/p&gt;
&lt;p&gt;We have our parameters and have set up logging. Next, we’ll read in the data stored &lt;a href=&#34;https://raw.githubusercontent.com/thecodeforest/codeforest_datasets/main/pyspark_forecasting_data/weekly_sales_data.csv&#34;&gt;here&lt;/a&gt; and execute some basic field formatting with &lt;em&gt;clean_names&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def clean_names(df: pd.DataFrame) -&amp;gt; pd.DataFrame:
    &amp;quot;&amp;quot;&amp;quot;Applies the following transformations to column names:
        - Removes camel case
        - Replaces any double underscore with single underscore
        - Removes spaces in the middle of a string name
        - Replaces periods with underscores

    Args:
        df (pd.DataFrame): Dataframe with untransformed column names

    Returns:
        pd.DataFrame: Dataframe with transformed column names
    &amp;quot;&amp;quot;&amp;quot;
    cols = df.columns
    cols = [re.sub(r&amp;quot;(?&amp;lt;!^)(?=[A-Z])&amp;quot;, &amp;quot;_&amp;quot;, x).lower() for x in cols]
    cols = [re.sub(r&amp;quot;_{2,}&amp;quot;, &amp;quot;_&amp;quot;, x) for x in cols]
    cols = [re.sub(r&amp;quot;\s&amp;quot;, &amp;quot;&amp;quot;, x) for x in cols]
    cols = [re.sub(r&amp;quot;\.&amp;quot;, &amp;quot;_&amp;quot;, x) for x in cols]
    df.columns = cols
    return df&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales_df = pd.read_csv(input_data_path)
sales_df = clean_names(sales_df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you don’t have a &lt;em&gt;clean_names&lt;/em&gt;-type function as part of your codebase, I’d highly recommend creating one. It’s a function that I use frequently when reading data from various sources and encourages a standardized way of formatting field names.&lt;/p&gt;
&lt;p&gt;Now that we have our data, we’ll do some pre-forecasting data cleaning. The main steps are outlined below:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Filter groups with limited observations&lt;/strong&gt; - It’s a good idea to put predictions against items where you have some historical data. While the space of &lt;a href=&#34;https://aws.amazon.com/blogs/machine-learning/now-available-in-amazon-sagemaker-deepar-algorithm-for-more-accurate-time-series-forecasting/&#34;&gt;cold-start forecasting&lt;/a&gt; is very interesting, it is outside the scope of this post. Thus, we are putting a minimum threshold on the number of data points per group. This is also a good idea because some forecasting algorithms will not fit a model against a few observations, causing your program to crash.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Replace negative values with zero&lt;/strong&gt; - I’m assuming a negative value represents a returned product. Our goal is to forecast &lt;strong&gt;demand&lt;/strong&gt; not &lt;strong&gt;demand - returns&lt;/strong&gt;. This is an assumption that would need to be validated with domain knowledge.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pad missing values&lt;/strong&gt; - Accounting for missing data is an easy step to overlook for one simple reason: Missing values in time-series data are not usually flagged as “missing”. For example, a store may shut down for six weeks of renovations. As a result, there will be a series of dates that have no sales data. Identifying these gaps is pivotal for generating reliable forecasts. I’ve provided a brief example below to illustrate what this looks like from a data perspective.&lt;/p&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#nbpomebbll .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#nbpomebbll .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nbpomebbll .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#nbpomebbll .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#nbpomebbll .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nbpomebbll .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nbpomebbll .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#nbpomebbll .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#nbpomebbll .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#nbpomebbll .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#nbpomebbll .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#nbpomebbll .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#nbpomebbll .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#nbpomebbll .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#nbpomebbll .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#nbpomebbll .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#nbpomebbll .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#nbpomebbll .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nbpomebbll .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#nbpomebbll .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nbpomebbll .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#nbpomebbll .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#nbpomebbll .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nbpomebbll .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nbpomebbll .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#nbpomebbll .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nbpomebbll .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#nbpomebbll .gt_left {
  text-align: left;
}

#nbpomebbll .gt_center {
  text-align: center;
}

#nbpomebbll .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#nbpomebbll .gt_font_normal {
  font-weight: normal;
}

#nbpomebbll .gt_font_bold {
  font-weight: bold;
}

#nbpomebbll .gt_font_italic {
  font-style: italic;
}

#nbpomebbll .gt_super {
  font-size: 65%;
}

#nbpomebbll .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;nbpomebbll&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34; style=&#34;table-layout: fixed;; width: 0px&#34;&gt;
  &lt;colgroup&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
  &lt;/colgroup&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;4&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;strong&gt;Incomplete Data&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;4&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;store&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;dept&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;date&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-05&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;24924&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-19&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;41596&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-26&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;19404&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-03-19&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;22137&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-03-26&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;26229&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#rggjwgclsv .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#rggjwgclsv .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rggjwgclsv .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#rggjwgclsv .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#rggjwgclsv .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rggjwgclsv .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rggjwgclsv .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#rggjwgclsv .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#rggjwgclsv .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#rggjwgclsv .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#rggjwgclsv .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#rggjwgclsv .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#rggjwgclsv .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#rggjwgclsv .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#rggjwgclsv .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#rggjwgclsv .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#rggjwgclsv .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#rggjwgclsv .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rggjwgclsv .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#rggjwgclsv .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rggjwgclsv .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#rggjwgclsv .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#rggjwgclsv .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rggjwgclsv .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rggjwgclsv .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#rggjwgclsv .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rggjwgclsv .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#rggjwgclsv .gt_left {
  text-align: left;
}

#rggjwgclsv .gt_center {
  text-align: center;
}

#rggjwgclsv .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#rggjwgclsv .gt_font_normal {
  font-weight: normal;
}

#rggjwgclsv .gt_font_bold {
  font-weight: bold;
}

#rggjwgclsv .gt_font_italic {
  font-style: italic;
}

#rggjwgclsv .gt_super {
  font-size: 65%;
}

#rggjwgclsv .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;rggjwgclsv&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34; style=&#34;table-layout: fixed;; width: 0px&#34;&gt;
  &lt;colgroup&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
  &lt;/colgroup&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;4&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;strong&gt;Padded Data&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;4&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;store&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;dept&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;date&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-05&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;24924&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-12&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-19&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;41596&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-26&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;19404&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-03-05&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-03-12&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-03-19&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;22137&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-03-26&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;26229&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;We’ll go back and fill or “interpolate” those missing values in the &lt;code&gt;weekly_sales&lt;/code&gt; field in a later step.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Filter groups with long ‘streaks’ of missing observations&lt;/strong&gt; - Building on the previous example, let’s say the store closes for six months instead of six weeks. Thus, half of the year will not have any sales information. We could fill it in with a reasonable value, such as the average, but this won’t capture the overall trend, seasonality, or potential holiday/event effects that help to explain variation in our outcome variable. I’ll often initially exclude these time-series, and then try to understand why/how long streaks of values are missing. In this case, we’ll set a limit of four weeks (i.e., if any time-series has more than four consecutive dates missing, exclude from the final forecasting step).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interpolate missing values&lt;/strong&gt; - Fills in missing data with “reasonable” values. We’ll use the overall mean of each series, which is a very simple and easy to understand technique. There are better approaches that account for seasonality or local trends. However, the goal here isn’t to generate the best forecast but instead to create a good starting point from which to iterate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Add forecasting bounds&lt;/strong&gt; - This function is specific to the Prophet API and is not required to generate a forecast via PySpark. However, when you cannot inspect the quality of each forecast, adding in some “guardrails” can prevent errant predictions that erode trust with your stakeholders. The &lt;code&gt;floor&lt;/code&gt; and &lt;code&gt;cap&lt;/code&gt; fields provide bounds that a forecast cannot go above or below. For example, if the minimum value in a time-series is 10 and the maximum is 100, a floor of 0.5 and a cap of 1.5 ensures all forecasted values are not above 150 (100 * 1.5) or less than 5 (10 * 0.5). Again, these decisions are often driven by domain knowledge of the forecaster. We’ll go a bit deeper on this field below as well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Log transform outcome variable&lt;/strong&gt; - Log transforming our outcome variable is an effective approach to reduce the influence of outliers and stabilize variance that increases over time. A separate approach is to use a box-cox transformation (see &lt;a href=&#34;https://otexts.com/fpp2/transformations.html&#34;&gt;here&lt;/a&gt; for more details), which can yield better results than a log-transformation. However, I often start with a log-transformation because it does require us to keep track of the transformation parameters, which is something you’ll need to do with a box-cox transformation. Are we seeing a theme here? Start simple.&lt;/p&gt;
&lt;p&gt;Whew - that was a lot of information, but we can finally implement all of these data-cleaning steps via the &lt;code&gt;FcastDataFrame&lt;/code&gt; class. The format was inspired by the &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html&#34;&gt;sklearn.pipeline class&lt;/a&gt; to prepare and clean grouped time-series data prior to generating forecasts.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;class FcastDataFrame:
    &amp;quot;&amp;quot;&amp;quot;Use for pre-processing data prior to forecasting&amp;quot;&amp;quot;&amp;quot;
    def __init__(
        self,
        df: pd.DataFrame,
        group_fields: List[str],
        date_field: str,
        yvar_field: str,
        ts_frequency: str,
    ):
        &amp;quot;&amp;quot;&amp;quot;
        Args:
            df (pd.DataFrame): dataframe with to be forecasted data
            group_fields (List[str]): grouping fields. These are often re
                represented by attributes of each unit 
                (e.g., store id, product id, etc.).
            date_field (str): date field
            yvar_field (str): outcome (&amp;quot;y&amp;quot;) field
            ts_frequency (str): granularity of the data. For example, 
                data that is recorded on a weekly basis, every Friday will 
                be &amp;quot;W-FRI&amp;quot;. Note that sub-day level (e.g, hourly, minute) 
                data is not supported. 
        &amp;quot;&amp;quot;&amp;quot;
        self.df = df
        self.group_fields = group_fields
        self.date_field = date_field
        self.yvar_field = yvar_field
        self.ts_frequency = ts_frequency
        
fcast_df = FcastDataFrame(
        df=sales_df,
        group_fields=group_fields,
        date_field=date_field,
        yvar_field=yvar_field,
        ts_frequency=ts_frequency,
    )        &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While we won’t cover all methods in this class, I’ll briefly review one of the methods – &lt;code&gt;filter_groups_min_obs&lt;/code&gt; – to illustrate the structure of the class.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def filter_groups_min_obs(self, min_obs_threshold: int):
    &amp;quot;&amp;quot;&amp;quot;Filters groups based on some minimum number of observations 
       required for forecasting

    Args:
        min_obs_threshold (int): removes all groups with less obsevations than 
                                 this threshold
    &amp;quot;&amp;quot;&amp;quot;
    n_unique_groups = self.df[self.group_fields].drop_duplicates().shape[0]
    min_obs_filter_df = (
        self.df.groupby(self.group_fields)[self.yvar_field]
        .count()
        .reset_index()
        .rename(columns={self.yvar_field: &amp;quot;obs_count&amp;quot;})
        .query(f&amp;quot;obs_count &amp;gt; {str(min_obs_threshold)}&amp;quot;)
        .drop(columns=&amp;quot;obs_count&amp;quot;)
    )
    n_remaining_groups = min_obs_filter_df.shape[0]
    df = pd.merge(self.df, min_obs_filter_df, how=&amp;quot;inner&amp;quot;, on=self.group_fields)
    self.df = df
    logger.info(&amp;quot;N groups dropped: {}&amp;quot;.format(n_unique_groups - n_remaining_groups))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each data transformation takes in our data, applies some filtering, cleaning, or formatting, logs the changes, and then replaces the existing DataFrame with the updated DataFrame. This pattern is applied at each step until we are satisfied with the changes. Let’s apply these filtering and cleaning steps below.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# filter out groups with less than min number of observations
fcast_df.filter_groups_min_obs(min_obs_threshold=min_obs_threshold)  
# replace any negative value with a zero
fcast_df.replace_negative_value_with_zero()
# replace missing dates between start and end of time-series by group
fcast_df.pad_missing_values()
# filter groups with consecutive missing streak longer than 4
fcast_df.filter_groups_max_missing_streak(max_streak=4)
# impute missing values
fcast_df.fill_missing_values()
# add upper and lower bounds for forecasting
fcast_df.add_forecast_bounds(
    floor_multiplier=fcast_floor, 
    cap_multiplier=fcast_cap
)
# log transform outcome, floor, and cap values
fcast_df.log_transform_values(yvar_field, &amp;quot;floor_value&amp;quot;, &amp;quot;cap_value&amp;quot;)
# return transformed data
fcast_df_trans = fcast_df.return_transformed_df()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we are ready to do some forecasting. In the next section, we’ll produce our forecasts from the cleaned and prepared data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pyspark-forecasting&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;a id=&#34;forecasting_section&#34;&gt;&lt;/a&gt; Pyspark Forecasting&lt;/h3&gt;
&lt;p&gt;Let’s start by translating the field names to those that Prophet understands. For example, our date variable should be named &lt;code&gt;ds&lt;/code&gt; and our outcome variable &lt;code&gt;y&lt;/code&gt;. We’ll use the &lt;em&gt;prep_for_prophet&lt;/em&gt; function to make the transition.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def prep_for_prophet(
    df: pd.DataFrame, yvar_field: str, date_field: str, group_fields: List[str]
) -&amp;gt; pd.DataFrame:
    &amp;quot;&amp;quot;&amp;quot;Renames key field names to be compatible with Prophet Forecasting API

    Args:
        df (pd.DataFrame): Contains data that will be used to generate forecasting
        yvar_field (str): outcome (&amp;quot;y&amp;quot;) field name
        date_field (str): date field name
        group_fields (List[str]): grouping fields. These are often
                represented by attributes of each unit
                (e.g., store id, product id, etc.).

    Returns:
        pd.DataFrame: Data with compatible field names
    &amp;quot;&amp;quot;&amp;quot;
    fields = df.columns.tolist()
    cap_value_index = [
        index 
        for index, value in enumerate([&amp;quot;cap_value&amp;quot; in x for x in fields]) 
        if value
    ]
    floor_value_index = [
        index
        for index, value in enumerate([&amp;quot;floor_value&amp;quot; in x for x in fields])
        if value
    ]
    if cap_value_index and floor_value_index:
        df = df.rename(
            columns={
                fields[cap_value_index[0]]: &amp;quot;cap&amp;quot;,
                fields[floor_value_index[0]]: &amp;quot;floor&amp;quot;,
            }
        )
        group_fields = group_fields + [&amp;quot;cap&amp;quot;, &amp;quot;floor&amp;quot;]
    df = df[group_fields + [date_field] + [yvar_field]]
    df = df.rename(columns={date_field: &amp;quot;ds&amp;quot;, yvar_field: &amp;quot;y&amp;quot;})
    df[&amp;quot;ds&amp;quot;] = pd.to_datetime(df[&amp;quot;ds&amp;quot;])
    return df&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fcast_df_prophet_input = prep_for_prophet(
        df=fcast_df_trans,
        yvar_field=&amp;quot;weekly_sales_prep_log1p&amp;quot;,
        date_field=date_field,
        group_fields=group_fields,
    )    &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With our data prepared, we’ll shift over to creating a Spark Session and indicate where our Java version is located. Note this step will vary depending on your computing environment.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;os.environ[&amp;quot;JAVA_HOME&amp;quot;] = java_home

SPARK = (
    SparkSession.builder.master(f&amp;quot;local[{spark_n_threads}]&amp;quot;)
    .appName(config[&amp;quot;app_name&amp;quot;])
    .config(&amp;quot;spark.sql.execution.arrow.pyspark.enabled&amp;quot;, &amp;quot;true&amp;quot;)
    .getOrCreate()
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we’ll define the schema (or format) of our input and output data.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;INPUT_SCHEMA = StructType(
        [
            StructField(&amp;quot;store&amp;quot;, IntegerType(), True),
            StructField(&amp;quot;dept&amp;quot;, IntegerType(), True),
            StructField(&amp;quot;cap&amp;quot;, FloatType(), True),
            StructField(&amp;quot;floor&amp;quot;, FloatType(), True),
            StructField(&amp;quot;ds&amp;quot;, DateType(), True),
            StructField(&amp;quot;y&amp;quot;, FloatType(), True),
        ]
    )
    
OUTPUT_SCHEMA = StructType(
        [
            StructField(&amp;quot;ds&amp;quot;, DateType(), True),
            StructField(&amp;quot;store&amp;quot;, IntegerType(), True),
            StructField(&amp;quot;dept&amp;quot;, IntegerType(), True),
            StructField(&amp;quot;yhat_lower&amp;quot;, FloatType(), True), 
            StructField(&amp;quot;yhat_upper&amp;quot;, FloatType(), True),
            StructField(&amp;quot;yhat&amp;quot;, FloatType(), True),
        ]
)    &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll now translate our Pandas DataFrame to a Spark DataFrame and pass in the schema we defined above.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fcast_spark_prophet_input = SPARK.createDataFrame(
        fcast_df_prophet_input, schema=INPUT_SCHEMA
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function below does the actual forecasting and we’ll spend some time unpacking what’s happening here.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def run_forecast(keys, df):
    &amp;quot;&amp;quot;&amp;quot;Generate time-series forecast 

    Args:
        keys: Grouping keys
        df: Spark Dataframe 
    &amp;quot;&amp;quot;&amp;quot;
    fields = [&amp;quot;ds&amp;quot;, &amp;quot;store&amp;quot;, &amp;quot;dept&amp;quot;, &amp;quot;yhat_lower&amp;quot;, &amp;quot;yhat_upper&amp;quot;,&amp;quot;yhat&amp;quot;]
    store, dept = keys
    cap = df[&amp;quot;cap&amp;quot;][0]
    floor = df[&amp;quot;floor&amp;quot;][0]
    model = Prophet(
        interval_width=0.95,
        growth=&amp;quot;logistic&amp;quot;,
        yearly_seasonality=True,
        seasonality_mode=&amp;quot;additive&amp;quot;,
    )
    model.add_country_holidays(country_name=&amp;quot;US&amp;quot;)
    model.fit(df)
    future_df = model.make_future_dataframe(
        periods=13, freq=&amp;quot;W-FRI&amp;quot;, include_history=False
    )
    future_df[&amp;quot;cap&amp;quot;] = cap
    future_df[&amp;quot;floor&amp;quot;] = floor
    results_df = model.predict(future_df)
    results_df[&amp;quot;store&amp;quot;] = store
    results_df[&amp;quot;dept&amp;quot;] = dept
    results_df = results_df[fields]
    return results_df&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s start by discussing the Prophet model, which automates the selection of many forecasting settings, like seasonality, determined during the model fitting process. Below is a brief summary of some of the key settings:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;interval_width&lt;/strong&gt; - Interval width quantifies uncertainty in our forecast. Wider intervals indicate greater uncertainty. Here, we are indicating that the actual values should fall outside of the interval ~5% of the time. By default, Prophet is set to 80%, which is less conservative than our setting here. Providing a measure of uncertainty is perhaps even more important than the forecast itself, as it allows a business to hedge against the risk of being wrong. For example, imagine a product has a high margin and a low inventory holding cost. In this instance, you would want to plan to a high percentile, as you rarely want to stock out of this product.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;yearly_seasonality&lt;/strong&gt; - Setting this to &lt;code&gt;True&lt;/code&gt; indicates my belief that there is week-over-week variation that repeats itself over the course of a year. For example, sales for items like sandals or sunscreen are likely higher in Summer weeks and lower in the Winter weeks. There are two other seasonality options not included above - &lt;code&gt;daily&lt;/code&gt; and &lt;code&gt;hourly&lt;/code&gt;. Daily captures hourly changes within a day, while hourly captures minute-by-minute changes within an hour. Our data is at the week level, so we can ignore these two settings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;growth&lt;/strong&gt; - Growth is a way to encode our beliefs regarding if a forecast should reach a “saturation” point across your prediction horizon (see &lt;a href=&#34;https://facebook.github.io/prophet/docs/saturating_forecasts.html&#34;&gt;here&lt;/a&gt; for official documentation). For example, customer acquisition slows as a market matures and will eventually reach a saturation point (i.e., the total addressable market has been acquired). This is typically used for “long-range” forecasting on the scale of several years. Our forecasting horizon is much shorter at only 13 weeks. However, I like to codify what I consider to be reasonable amount of growth, via the “cap” parameter, as well as contraction, via the “floor” parameter, in my forecasts, especially when I cannot inspect each result.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;seasonality_mode&lt;/strong&gt; - I’ve selected “additive” for this parameter based on my belief that the magnitude of seasonal changes do not vary across time. Recall that our outcome variable has already been log-transformed, thus we are actually using an additive decomposition of the log-transformed values.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;add_country_holidays&lt;/strong&gt; - Holidays tend to drive increases in consumption of particular products. And some holidays, like Easter, are not consistent year-over-year. Thus, you can improve forecasting accuracy if you anticipate how demand shifts when generating forecasts based on when holidays occur. One thing to note that is not included in the current post (but is incredibly useful) is the ability to apply a &lt;code&gt;lower_window&lt;/code&gt; and &lt;code&gt;upper_window&lt;/code&gt; to each holiday date. Continuing with our Easter example, you can imagine egg sales increase in the days leading up to Easter. Sales on the holiday date may not be that high, unless you are doing some last minute shopping. By extending the &lt;code&gt;lower_window&lt;/code&gt; parameter for this holiday to something like -5, you can capture the elevated demand during the five days that precede Easter.&lt;/p&gt;
&lt;p&gt;Now that we are familiar with how the model is being tuned, let’s generate the forecasts. This may take a few minutes depending on how many threads you are using. I am using four, and it took about 20 minutes to complete.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fcast_df_prophet_output = (
    fcast_spark_prophet_input.groupBy(group_fields)
    .applyInPandas(func=run_forecast, schema=OUTPUT_SCHEMA)
    .withColumn(&amp;quot;part&amp;quot;, lit(&amp;quot;forecast&amp;quot;))
    .withColumn(&amp;quot;fcast_date&amp;quot;, lit(datetime.now().strftime(&amp;quot;%Y-%m-%d&amp;quot;)))
    .toPandas()
    .rename(
        columns={
            &amp;quot;yhat&amp;quot;: yvar_field,
            &amp;quot;yhat_lower&amp;quot;: f&amp;quot;{yvar_field}_lb&amp;quot;,
            &amp;quot;yhat_upper&amp;quot;: f&amp;quot;{yvar_field}_ub&amp;quot;,
            &amp;quot;ds&amp;quot;: date_field,
        }
    )
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We should have 13-week forecasts for all store-department combinations. Our next steps are to combine the forecasts with the historical data and invert our log-transformation of the outcome variable to get back to our original scale. Note that &lt;code&gt;np.log1p&lt;/code&gt; and &lt;code&gt;np.expm1&lt;/code&gt; are inverses of one another, and elegantly deal with zero values by adding/subtracting a value of “1” to avoid taking the log of zero, which is undefined and will make your code go 💥. Lastly, we’ll write the results out to our root directory.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;fcast_df_prophet_input[&amp;quot;part&amp;quot;] = &amp;quot;actuals&amp;quot;
fcast_df_prophet_input = fcast_df_prophet_input.rename(
    columns={&amp;quot;y&amp;quot;: yvar_field, &amp;quot;ds&amp;quot;: date_field}
)
del fcast_df_prophet_input[&amp;quot;cap&amp;quot;]
del fcast_df_prophet_input[&amp;quot;floor&amp;quot;]

ret_df = pd.concat([fcast_df_prophet_input, fcast_df_prophet_output])
ret_df = ret_df.apply(lambda x: round(np.expm1(x)) if yvar_field in x.name else x)

ret_df.to_csv(Path.cwd() / &amp;quot;sales_data_forecast.csv&amp;quot;, index=False)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quality-assurance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Quality Assurance&lt;/h3&gt;
&lt;p&gt;We’ll transition back to the world of R for some quick quality-assurance work. Let’s read in our forecasts and examine a few store-department combinations. Note there are much more formal ways to validate the performance of our models, but our objective is to do a quick sanity check (i.e., “do the forecasts look reasonable for a few randomly sampled grouped?”). The raw output is stored in &lt;a href=&#34;https://raw.githubusercontent.com/thecodeforest/codeforest_datasets/main/pyspark_forecasting_data/sales_data_forecast.csv&#34;&gt;Github&lt;/a&gt;. Let’s start by examining the first and last five rows for a single Store-Dept combination.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(timetk)
library(lubridate)

fcast_df_url = &amp;quot;https://raw.githubusercontent.com/thecodeforest/codeforest_datasets/main/pyspark_forecasting_data/sales_data_forecast.csv&amp;quot;
fcast_df = read_csv(fcast_df_url)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_store_dept_sample &amp;lt;- fcast_df %&amp;gt;% 
  filter(store == 1, dept == 1) %&amp;gt;% 
  mutate(date = as_date(date))&lt;/code&gt;&lt;/pre&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#vajqssudrv .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 9px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#vajqssudrv .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vajqssudrv .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#vajqssudrv .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#vajqssudrv .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vajqssudrv .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vajqssudrv .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#vajqssudrv .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#vajqssudrv .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#vajqssudrv .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#vajqssudrv .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#vajqssudrv .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#vajqssudrv .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#vajqssudrv .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#vajqssudrv .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#vajqssudrv .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#vajqssudrv .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#vajqssudrv .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vajqssudrv .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#vajqssudrv .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vajqssudrv .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#vajqssudrv .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#vajqssudrv .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vajqssudrv .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vajqssudrv .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#vajqssudrv .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vajqssudrv .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#vajqssudrv .gt_left {
  text-align: left;
}

#vajqssudrv .gt_center {
  text-align: center;
}

#vajqssudrv .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#vajqssudrv .gt_font_normal {
  font-weight: normal;
}

#vajqssudrv .gt_font_bold {
  font-weight: bold;
}

#vajqssudrv .gt_font_italic {
  font-style: italic;
}

#vajqssudrv .gt_super {
  font-size: 65%;
}

#vajqssudrv .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;vajqssudrv&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34; style=&#34;table-layout: fixed;; width: 0px&#34;&gt;
  &lt;colgroup&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
  &lt;/colgroup&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;8&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;strong&gt;Top 5 Rows of Forecasting Data&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;8&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;store&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;dept&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;date&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly_sales&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;part&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly_sales_lb&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly_sales_ub&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;fcast_date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-05&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;24924&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;actuals&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-12&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;46039&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;actuals&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-19&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;41596&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;actuals&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-02-26&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;19404&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;actuals&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2010-03-05&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;21828&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;actuals&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;NA&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#uwmuwyxmsv .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 9px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#uwmuwyxmsv .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#uwmuwyxmsv .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#uwmuwyxmsv .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#uwmuwyxmsv .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#uwmuwyxmsv .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#uwmuwyxmsv .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#uwmuwyxmsv .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#uwmuwyxmsv .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#uwmuwyxmsv .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#uwmuwyxmsv .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#uwmuwyxmsv .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#uwmuwyxmsv .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#uwmuwyxmsv .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#uwmuwyxmsv .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#uwmuwyxmsv .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#uwmuwyxmsv .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#uwmuwyxmsv .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#uwmuwyxmsv .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#uwmuwyxmsv .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#uwmuwyxmsv .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#uwmuwyxmsv .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#uwmuwyxmsv .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#uwmuwyxmsv .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#uwmuwyxmsv .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#uwmuwyxmsv .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#uwmuwyxmsv .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#uwmuwyxmsv .gt_left {
  text-align: left;
}

#uwmuwyxmsv .gt_center {
  text-align: center;
}

#uwmuwyxmsv .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#uwmuwyxmsv .gt_font_normal {
  font-weight: normal;
}

#uwmuwyxmsv .gt_font_bold {
  font-weight: bold;
}

#uwmuwyxmsv .gt_font_italic {
  font-style: italic;
}

#uwmuwyxmsv .gt_super {
  font-size: 65%;
}

#uwmuwyxmsv .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;uwmuwyxmsv&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34; style=&#34;table-layout: fixed;; width: 0px&#34;&gt;
  &lt;colgroup&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
    &lt;col style=&#34;width:75px;&#34;/&gt;
  &lt;/colgroup&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;8&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;strong&gt;Bottom 5 Rows of Forecasting Data&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;8&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;store&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;dept&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;date&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly_sales&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;part&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly_sales_lb&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;weekly_sales_ub&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;fcast_date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2012-12-28&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;30948&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;forecast&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;21883&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;42839&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2021-04-05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2013-01-04&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;21138&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;forecast&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;14793&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;30024&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2021-04-05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2013-01-11&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;16149&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;forecast&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;11384&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;22832&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2021-04-05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2013-01-18&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;15553&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;forecast&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;10712&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;21662&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2021-04-05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2013-01-25&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;18954&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;forecast&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;13475&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;27282&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2021-04-05&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;Let’s sample a few forecasts and plot them out.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2021)
fcast_df %&amp;gt;% 
  filter(store &amp;lt; 3,
         dept %in% c(df %&amp;gt;% distinct(dept) %&amp;gt;% sample_n(2) %&amp;gt;% pull())
         ) %&amp;gt;% 
  mutate(store = paste0(&amp;#39;Store: &amp;#39;, store),
         dept = paste0(&amp;#39;Dept: &amp;#39;, dept),
         store_id = paste(store, dept, sep=&amp;#39; &amp;#39;)) %&amp;gt;% 
  select(date, store_id, contains(&amp;#39;weekly&amp;#39;)) %&amp;gt;% 
  pivot_longer(contains(&amp;#39;weekly&amp;#39;)) %&amp;gt;%  
  mutate(name = str_to_title(str_replace_all(name, &amp;#39;_&amp;#39;, &amp;#39; &amp;#39;))) %&amp;gt;% 
  ggplot(aes(date, value, color = name)) + 
  geom_line(size = 1.5, alpha = 0.8) + 
  facet_grid(store_id ~ ., scales = &amp;#39;free&amp;#39;) + 
  theme_bw() + 
  scale_y_continuous(labels = scales::comma_format()) + 
  labs(x = &amp;#39;Date&amp;#39;,
       y = &amp;#39;Weekly Sales&amp;#39;,
       color = NULL,
       title = &amp;#39;Sample Forecasts&amp;#39;
       ) + 
  theme(legend.position = &amp;quot;top&amp;quot;,
        legend.text = element_text(size = 12),
        strip.text.y = element_text(size = 12),
        plot.title = element_text(size = 14)
        )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-03-28-pyspark-forecasting/pyspark_time_series_forecasting_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Overall, the forecasts appear to capture changes in the trend and seasonal variation. A more formal approach to this problem is to do back-testing by holding out some historical data and generating forecasts against it. However, this is a great starting point from which to build more advanced models and incorporate external variables to further improve our forecasts. Hopefully this is enough to get you started on your way to forecasting at an enterprise scale. Until next time, happy forecasting!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Causal Inference with Propensity Scores</title>
      <link>http://example.org/post/2021-05-01-propensity-scores/causal_inference_propensity_scores/</link>
      <pubDate>Mon, 15 Mar 2021 21:13:14 -0500</pubDate>
      <guid>http://example.org/post/2021-05-01-propensity-scores/causal_inference_propensity_scores/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-03-15-causal-inference-pt-1/images/dag.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;p&gt;Causal inference attempts to answer “what-if” questions. For example, if the minimum wage were increased, what effect would it have on unemployment rates? Or if an entertainment company launched a marketing campaign for a new movie, what effect would it have on box-office sales? The objective in each of these examples is to quantify the impact of an intervention – a change in wages or a targeted marketing campaign – on an outcome – increasing employment or bolstering revenue. Estimating how a particular action can affect an end-state falls within the realm of &lt;em&gt;prescriptive&lt;/em&gt; analytics and can inform decision-making in the face of multiple possible actions.&lt;/p&gt;
&lt;p&gt;However, most analytics efforts are applied to either &lt;em&gt;describing&lt;/em&gt; or &lt;em&gt;predicting&lt;/em&gt; an outcome rather than understanding what drives it. For example, imagine you work for a cheese shop. You might be asked to &lt;em&gt;describe&lt;/em&gt; how sales of cheese have changed over the past year. Or perhaps you want to &lt;em&gt;predict&lt;/em&gt; how much cheese will sell over the next 12 months. Descriptive analytics can reveal if existing operational or strategic decisions are impacting the business (i.e., cheese sales) as anticipated. Predictive analytics can inform operational planning (e.g., how much cheese to manufacture), improve consumer experiences (e.g., an online cheese recommendation system), or automate repetitive tasks (e.g., automatically detecting defective cheese wheels during production with computer vision). While all of the applications can provide valuable answers to different questions, none can provide insight into the source of variation or root cause(s) of change in an outcome. Without this knowledge, it can be difficult to know where resources should be focused or how to grow and improve the business.&lt;/p&gt;
&lt;p&gt;Accordingly, the goal of this post is to highlight one approach to conducting prescriptive analytics and generating causal inferences with observational data. We’ll first walk through some of the basics of causal inference and propensity scores, followed by a practical example that brings these concepts together. At the end of this post, you should have a solid understanding of how propensity scores can be used in the real world to guide decision-making.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;causal-inference-propensity-scores&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Causal Inference &amp;amp; Propensity Scores&lt;/h3&gt;
&lt;p&gt;When people hear the words “causal inference”, they often think “A/B Test”. Indeed, the traditional way of answering causal questions is to randomly assign individuals to a treatment or control condition. The treatment is exposed to the intervention, while the control is not. The average difference is then calculated between the two conditions on some measure of interest to understand if the intervention had the desired effect.&lt;/p&gt;
&lt;p&gt;While A/B testing is considered the most rigorous way of inferring causation, it is not practical or possible in many situations. For example, if you were interested in the effect of a membership program on future purchasing behavior, you cannot assign customers to be a member or non-member; customers would enroll in the program under their own volition. Further, customers who enrolled as members are probably more interested in the product than those who did not enroll. This fact “confounds” the relationship between the effect of our member program on purchasing behavior.&lt;/p&gt;
&lt;p&gt;Propensity score matching attempts to address this issue, known as &lt;em&gt;selection bias&lt;/em&gt;, by adjusting for factors that relate both to the treatment and outcome (i.e., confounding variables). A propensity score is scaled from 0 - 1 and indicates the probability of receiving treatment. Continuing with our previous membership example, a propensity score indicates the probability that a customer joins our membership program after seeing a banner on our website or receiving a promotional email. It does not indicate their probability of making a future purchase. Formalizing the roles of individual variables that increase/decrease membership enrollment and their interrelations is the topic of the next section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;causal-graphs&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Causal Graphs&lt;/h3&gt;
&lt;p&gt;We can codify our beliefs and assumptions about observational data through a &lt;em&gt;causal graph&lt;/em&gt;. This is normally the first step on our journey of causal inference, as it allows us to translate domain knowledge into a formal structure. By creating a diagram about potential confounding variables as well as the direction of causal influence, we make our assumptions about the data generating process explicit.&lt;/p&gt;
&lt;p&gt;In the context of the current example, we assume that a customer in enrolling as a member influences future purchase behavior, not that future purchase behavior influences enrollment in membership. We can then encode this assumption in our causal graph. The exclusion of certain variables from our graph (e.g., age, gender, what types of products someone has previously purchased, etc.) is also an assumption, such that we assume these variables do not directly or indirectly affect purchase frequency or membership.&lt;/p&gt;
&lt;p&gt;These assumptions can and should be verified. If we believe a customer’s age affects purchase frequency and membership enrollment, we can stratify our customers by age (i.e,., 20-29, 30-39) and test both hypotheses. If there were significant differences between groups, we would include an age variable in our graph and adjust for its influence on the treatment and outcome.&lt;/p&gt;
&lt;p&gt;This is a contrived example, so we’ll keep things simple and formalize the main components of our analysis as follows:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-03-15-causal-inference-pt-1/images/dag.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Purchase Frequency&lt;/strong&gt; - the total number of purchases six months following the launch of our membership program. This is our outcome variable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Membership&lt;/strong&gt; - if a customer enrolled as a member since the launch of the membership program. This is our treatment variable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Engagement&lt;/strong&gt; - this is an example of a latent variable. We would use several variables in practice but, to keep things simple, we’ll only use prior purchase history, defined as the total number of purchases in the six months before the launch of the membership program. This variable will serve as a proxy for Engagement. We assume that customers who have made more purchases in the past six months will be inclined to make more purchases in the future – that is, more engaged in the past translates into more engaged in the future. We also assume that this (partially) motivates membership enrollment. Engaged customers will not only purchase more frequently but also be more interested in exclusive offers and discounts – a few benefits provided to members – relative to customers that have historically purchased infrequently.&lt;/p&gt;
&lt;p&gt;The image above was created via the &lt;a href=&#34;http://dagitty.net/&#34;&gt;daggity website&lt;/a&gt;, which makes it easy to create Causal DAGs or Directed Acyclic Graphs. Note the goal of creating a propensity score is to block the arrow from &lt;strong&gt;Engagement&lt;/strong&gt; to &lt;strong&gt;Purchase Frequency&lt;/strong&gt;. This addresses the issue of &lt;em&gt;selection bias&lt;/em&gt;, in that our customers can “select into” the member condition. By adjusting for this pre-existing difference, we are attempting to make this bias &lt;em&gt;strongly ignorable&lt;/em&gt;, similar to a randomized experiment.&lt;/p&gt;
&lt;p&gt;Another aspect to consider is when an individual joined our membership program. We want to allow enough time for differences to emerge, so ideally a few months have elapsed so we can see what happens. Second, membership offers and the quality may change over time, just as the consumer’s relationship with our brand changes. By narrowing the time frame of analysis, we can further control for time-related factors.&lt;/p&gt;
&lt;p&gt;Last, we want to time-bound prior purchase history. Some customers may have frequently purchased in the past but have not been active for several years (or churned completely). We want to ensure that all customers in our sample have a chance of being exposed to the treatment. Thus, we could apply simple logic to narrow our consideration set, such as “all customers that have engaged with the brand in some capacity (e.g., made a purchase, browsed the website, or opened a marketing communication) since the start of our member program”. This is not a hard-and-fast rule but something to consider when deciding which individuals to include in your analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimating-the-effect-of-membership-on-purchase-frequency&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Estimating the Effect of Membership on Purchase Frequency&lt;/h3&gt;
&lt;p&gt;Now that we have a solid conceptual foundation, let’s continue to work through our membership example by generating some contrived data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(broom)
library(rsample)
library(janitor)
# set base theme as black &amp;amp; white
theme_set(theme_bw())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2021)
# sample size of members and non-members
n = 5000
# expected purchase frequency
base_lambda = .75
# purchase frequency effect size for &amp;quot;more engaged&amp;quot; customers 
engagement_effect_size = .25

less_engaged = rpois(n=n, lambda = base_lambda)
more_engaged = rpois(n=n, lambda = base_lambda + engagement_effect_size)
# create tibble with number of previous purchases for each customer
purchase_df &amp;lt;- tibble(n_purchase_pre = c(less_engaged, more_engaged))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the code block above, we expect “less engaged” customers to make 0.75 purchases (on average) over six months, and “more engaged” customers to make one purchase over the same period. The difference in purchase frequency between our customer types is ascribed to our latent variable of Engagement. We assume the data generating process for historical purchase frequency can be represented by the Poisson distribution. Recall that the Poisson distribution models the number of events expected to occur within a given period. It also approximates consumer purchase frequency patterns in the real world, such that most customers make a small number of purchases, while a few customers make a large number of purchases.&lt;/p&gt;
&lt;p&gt;We established our expected purchase frequency and engagement effect size above,so let’s simulate the effect of Engagement on Membership. We’ll create three bins and assign a probability of enrolling as a member within each bin, such that higher bins (i.e., the top 33% of customers) have a higher probability of enrolling relative to lower bins (i.e., the bottom 33% of customers).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;membership_sim &amp;lt;- function(bin){
  if(bin == 1){
    return(rbinom(1, 1, prob = 0.2))
  } else if (bin == 2){
    return(rbinom(1, 1, prob = 0.3))
  } else {
    return(rbinom(1, 1, prob = 0.4))
  }
}

purchase_df &amp;lt;- purchase_df %&amp;gt;% 
  mutate(bin = ntile(n_purchase_pre, 3),
         member_enrolled = map_int(bin, membership_sim)
         ) %&amp;gt;% 
  select(-bin)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While we know the true effect size (given that we generated the numbers), let’s verify the assumption that our proxy for engagement (Prior Purchases) exhibits the hypothesized effect on membership.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;purchase_df %&amp;gt;% 
  mutate(n_purchase_pre = fct_lump(as.factor(n_purchase_pre), 
                                   n=2,
                                   other_level = &amp;#39;2 or More&amp;#39;
                                   )) %&amp;gt;% 
  group_by(n_purchase_pre) %&amp;gt;% 
  summarise(pct_member = mean(member_enrolled)) %&amp;gt;% 
  ggplot(aes(n_purchase_pre, pct_member)) + 
  theme_bw() + 
  geom_col() + 
  coord_flip() + 
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
  labs(x = &amp;#39;N Prior Purchases&amp;#39;,
       y = &amp;#39;Percent Enrolled as Members&amp;#39;
       ) + 
  theme(axis.text.x = element_text(size = 12, angle = 90),
    axis.text.y = element_text(size = 14),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    legend.text = element_text(size = 14),
    legend.title = element_text(size = 16),
    strip.text.y = element_text(size = 14)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-05-01-propensity-scores/causal_inference_propensity_scores_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now that we have validated the relationship between these variables, we’ll create the joint effect of treatment (Membership) and our single covariate (Engagement) on our outcome (Purchase Frequency).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;purchase_sim &amp;lt;- function(n_purchase_pre, member_enrolled){
  membership_effect_size = .1
  if(member_enrolled == 1){
    post_purchase_freq = rpois(n=1, lambda=n_purchase_pre + membership_effect_size)
    return(post_purchase_freq)
  } else {
    post_purchase_freq = rpois(n=1, lambda=n_purchase_pre)
    return(post_purchase_freq)
  }
}

purchase_df &amp;lt;- purchase_df %&amp;gt;% 
  mutate(n_purchase_post = map2_int(n_purchase_pre, 
                                member_enrolled, 
                                purchase_sim)
         )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;purchase_sim&lt;/code&gt; function accounts for the number of prior purchases as well as if the customer has enrolled as a member. If they have enrolled, the true effect size is .1, in that enrolling a customer as a member leads to .1 additional purchases (on average) during the six months.&lt;/p&gt;
&lt;p&gt;Below, we’ll confirm that members have made more purchases relative to non-members.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avg_purchase_freq &amp;lt;- purchase_df %&amp;gt;% 
  group_by(member_enrolled) %&amp;gt;% 
  summarise(avg_post_purchase = mean(n_purchase_post),
            se = sqrt(mean(n_purchase_post) / n())
            ) %&amp;gt;% 
  mutate(is_member = str_to_title(ifelse(member_enrolled == 1, 
                                         &amp;#39;member&amp;#39;, 
                                         &amp;#39;non-member&amp;#39;)),
         is_member = fct_reorder(is_member, avg_post_purchase),
         lb = avg_post_purchase - 1.96 * se,
         ub = avg_post_purchase + 1.96 * se
         )

avg_purchase_freq %&amp;gt;% 
  ggplot(aes(is_member, avg_post_purchase, fill = is_member)) + 
  geom_col(color = &amp;#39;black&amp;#39;) + 
  geom_errorbar(aes(ymin = lb, ymax=ub), width=0.4) + 
  coord_flip() + 
  labs(x = NULL,
       y = &amp;#39;Average Number of Purchases&amp;#39;,
       fill = &amp;#39;Membership Status&amp;#39;
  ) + 
  theme(axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size = 12),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 16),
        legend.position = &amp;#39;top&amp;#39;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-05-01-propensity-scores/causal_inference_propensity_scores_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Indeed, this confirms that the data aligns with our expectations. We could reach the same conclusion by fitting a regression model and then considering the magnitude of the coefficient for membership.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;incorrect_fit &amp;lt;- glm(n_purchase_post ~ member_enrolled,
                     data = purchase_df,
                     family = &amp;quot;poisson&amp;quot;
                     )

incorrect_fit_coef &amp;lt;- tidy(incorrect_fit)

intercept &amp;lt;- incorrect_fit_coef %&amp;gt;% 
  filter(term == &amp;#39;(Intercept)&amp;#39;) %&amp;gt;% 
  pull(estimate)

member_est &amp;lt;- incorrect_fit_coef %&amp;gt;% 
  filter(term == &amp;#39;member_enrolled&amp;#39;) %&amp;gt;% 
  pull(estimate)

effect_size_est &amp;lt;- round(exp(intercept + member_est) - exp(intercept), 3)
print(glue::glue(&amp;#39;Estimated Difference: {effect_size_est}&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated Difference: 0.402&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that if we did not adjust for any confounding variables, we would &lt;strong&gt;mistakenly conclude&lt;/strong&gt; that membership leads to ~.3 extra purchases per customer. That is, we would overestimate the effect size of membership on customer purchase behaviors because we know that Engagement affects both Membership and Purchase Frequency. In the following section, we’ll generate propensity scores to create more balance between our control and treatment groups on our confounding variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;propensity-scores&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Propensity Scores&lt;/h3&gt;
&lt;p&gt;Two common approaches for creating comparison groups with observational data are (1) &lt;em&gt;propensity score matching&lt;/em&gt; and (2) &lt;em&gt;inverse probability of treatment weighting (IPTW)&lt;/em&gt;. Both methods use a propensity score but create groups differently. Matching looks for individuals in the non-treated condition who have similar propensity scores to those in the treated condition. If groups are different sizes, the number of non-treated observations is reduced to the size of the treated condition, as each treated observation is matched with a non-treated observation. In contrast, weighting includes all observations but places more weight on observations with high propensity scores and less weight on observations with low propensity scores. While both approaches can yield similar results, I prefer weighting because you are not discarding any data.&lt;/p&gt;
&lt;p&gt;Below, we’ll specify our model for generating propensity scores.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# specify model for estimating P(treatment | Previous Purchases)
model_spec &amp;lt;- as.formula(member_enrolled ~ n_purchase_pre)
member_model &amp;lt;- glm(model_spec, 
                    data = purchase_df, 
                    family = binomial())
member_prop_df &amp;lt;- member_model %&amp;gt;% 
  augment(type.predict = &amp;#39;response&amp;#39;, data = purchase_df) %&amp;gt;% 
  select(member_enrolled, n_purchase_pre, n_purchase_post, member_prob = .fitted) %&amp;gt;% 
  mutate(iptw = 1 / ifelse(member_enrolled == 0, 1 - member_prob, member_prob))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A few things to note since we’ve created our propensity scores. First, we used logistic regression to estimate membership probability. However, any classification model can generate a propensity score. If there are non-linearities between your covariates and treatment variable, using a model that can better capture these relationships, such as a tree-based model, may yield better estimates.&lt;/p&gt;
&lt;p&gt;Second, we’ll need to be cognizant of the resulting weights. If certain observations receive very large weights, they will have an outsized influence on our coefficient estimates. It is a common practice to truncate large weights at 10 (why 10 I’m not sure). I’d prefer to use a point from our actual distribution, so we’ll assign any value above the 99th percentile to the value at the 99th percentile.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iptw_pct_99 &amp;lt;- quantile(member_prop_df %&amp;gt;% pull(iptw), 0.99)[[1]]
member_prop_df &amp;lt;- member_prop_df %&amp;gt;% 
  mutate(iptw = ifelse(iptw &amp;gt; iptw_pct_99, iptw_pct_99, iptw))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we’ve addressed some common pre-modeling issues, let’s generate an initial estimate of the effect of Membership on Purchase Frequency.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;membership_fit &amp;lt;- glm(n_purchase_post ~ member_enrolled,
              data = member_prop_df,
              family = &amp;#39;poisson&amp;#39;,
              weights = iptw
              )
membership_fit_coef &amp;lt;- tidy(membership_fit)

intercept &amp;lt;- membership_fit_coef %&amp;gt;% 
  filter(term == &amp;#39;(Intercept)&amp;#39;) %&amp;gt;% 
  pull(estimate)

member_est &amp;lt;- membership_fit_coef %&amp;gt;% 
  filter(term == &amp;#39;member_enrolled&amp;#39;) %&amp;gt;% 
  pull(estimate)

effect_size_est_adj &amp;lt;- round(exp(intercept + member_est) - exp(intercept), 3)
print(glue::glue(&amp;#39;Estimated Difference: {effect_size_est_adj}&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated Difference: 0.097&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our initial estimate indicates that membership leads to ~.1 extra purchases, which matches perfectly with the true effect size! This is a great start, but we also need to consider certainty in the estimate. In our example, we have a fairly large sample size, there is only one covariate, and the distribution of treatment (members vs. non-members) is relatively even between groups. Real world data sets, on the other hand, are often small, present a high degree of skew between groups, or exhibit intricate causal structures. The presence of these factors affects how accurately we can estimate a true effect, and using the method above to create a confidence interval can lead to incorrect estimates of our standard error (too small).
To address this issue, we’ll bootstrap the entire process - from generating our propensity score weights to estimating our causal effect - and then use the resulting distribution to better quantify uncertainty in our estimate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;member_fit_bootstrap &amp;lt;- function(split){
  temp_df &amp;lt;- analysis(split)
  
  temp_model &amp;lt;- glm(member_enrolled ~ n_purchase_pre,
                    family = binomial(),
                    data = temp_df
                  )
  
  temp_df &amp;lt;- temp_model %&amp;gt;% 
    augment(type.predict = &amp;#39;response&amp;#39;, data = temp_df) %&amp;gt;% 
    select(member_enrolled, n_purchase_pre, 
           n_purchase_post, member_prob = .fitted) %&amp;gt;% 
    mutate(iptw = 1 / ifelse(member_enrolled == 0, 
                             1 - member_prob, 
                             member_prob))
  
  temp_iptw_pct_99 &amp;lt;- quantile(temp_df %&amp;gt;% pull(iptw), 0.99)[[1]]
  
  temp_df &amp;lt;- temp_df %&amp;gt;% 
    mutate(iptw = ifelse(iptw &amp;gt; temp_iptw_pct_99, 
                         temp_iptw_pct_99, 
                         iptw))
  
  temp_ret_df &amp;lt;- glm(n_purchase_post ~ member_enrolled,
                data = temp_df,
                family = &amp;#39;poisson&amp;#39;,
                weights = iptw) %&amp;gt;% 
    tidy()
  return(temp_ret_df)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_boot = 500
boot_results &amp;lt;- bootstraps(purchase_df, n_boot, apparent = TRUE) %&amp;gt;% 
  mutate(results = map(splits, member_fit_bootstrap))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above code snippet, we created 500 boot-strapped replicates and then fit a model to each. Our next step is to look at the distribution of the resulting estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot_results_unnest &amp;lt;- 
  boot_results %&amp;gt;% 
  select(-splits) %&amp;gt;% 
  unnest(cols=results)

boot_results_est &amp;lt;- 
  boot_results_unnest %&amp;gt;% 
  select(id, term, estimate) %&amp;gt;% 
  pivot_wider(names_from = term, 
              values_from = estimate
              ) %&amp;gt;% 
  clean_names() %&amp;gt;% 
  mutate(est_effect = exp(member_enrolled + intercept) - exp(intercept))


boot_results_summary &amp;lt;- boot_results_est %&amp;gt;%
  summarise(lb = quantile(est_effect, 0.025),
            mdn = quantile(est_effect, 0.5),
            ub = quantile(est_effect, 0.975)
  ) %&amp;gt;%
  pivot_longer(everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lb_est &amp;lt;- boot_results_summary %&amp;gt;% filter(name==&amp;#39;lb&amp;#39;) %&amp;gt;% pull(value)
ub_est &amp;lt;- boot_results_summary %&amp;gt;% filter(name==&amp;#39;ub&amp;#39;) %&amp;gt;% pull(value)
effect_est &amp;lt;- boot_results_summary %&amp;gt;% filter(name==&amp;#39;mdn&amp;#39;) %&amp;gt;% pull(value)
boot_results_est %&amp;gt;% 
  ggplot(aes(x=est_effect)) + 
  geom_histogram(fill=&amp;#39;grey90&amp;#39;, color = &amp;#39;black&amp;#39;) + 
  theme_bw() + 
  geom_segment(aes(x=lb_est, xend = lb_est), y = 0, yend = 10, lty = 3, size = 2) + 
  geom_segment(aes(x=effect_est, xend = effect_est), y = 0, yend = 10, lty = 3, size = 2) + 
  geom_segment(aes(x=ub_est, xend = ub_est), y = 0, yend = 10, lty = 3, size = 2) + 
  annotate(geom=&amp;#39;text&amp;#39;, x=lb_est, y = 11, label = round(lb_est, 2), size = 8) + 
  annotate(geom=&amp;#39;text&amp;#39;, x=effect_est, y = 11, label = round(effect_est, 2), size = 8) + 
  annotate(geom=&amp;#39;text&amp;#39;, x=ub_est, y = 11, label = round(ub_est, 2), size = 8) + 
  labs(x = &amp;#39;Estimated Treatment Effect&amp;#39;) + 
  theme(
    axis.text.x = element_text(size = 14),
    axis.text.y = element_text(size = 14),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-05-01-propensity-scores/causal_inference_propensity_scores_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our final estimate of the causal effect of membership on purchase frequency is between 0.06 and 0.14. Note that these confidence intervals aren’t much different from those in the original, non-bootstrapped approach. As mentioned previously, the primary reason is that our sample size for both groups is fairly large and there is not a lot of variance in the determinants of membership, given that we generated the data. However, in many instances, confidence intervals following bootstrapping will be wider – and more accurate – than those provided by OLS.&lt;/p&gt;
&lt;p&gt;Hopefully, this provided a solid end-to-end walkthrough of how to generate causal inferences from observational data with propensity scores. In the next post, we’ll discuss an equally important topic – variance reduction methods – that come in handy when you can run a true A/B test. Until then, happy experimenting!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Choosing a Fantasy Football Kicker with Emperical Bayes Estimation</title>
      <link>http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers/</link>
      <pubDate>Mon, 26 Aug 2019 21:13:14 -0500</pubDate>
      <guid>http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;http://example.org/post/2019-08-29-fantasy-football-kickers/images/header_image.jpg&#34; width=&#34;700&#34; height=&#34;400&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;p&gt;In less than two weeks, Fantasy Football will once again resume for the 2019 NFL season! While I’m looking forward to the impending draft, the start of the season brings back memories of a not-so-distant loss that left me one game shy of the championship. The loss stemmed from a missed field goal, leaving my team two points shy of victory. Of course, a myriad of factors beyond that missed field goal contributed to my fantasy demise, but those two points reinvigorated a question I’ve wondered about for the past few years: Why are kickers drafted in the last round?&lt;/p&gt;
&lt;p&gt;Prevailing wisdom suggests that your kicker doesn’t matter. Some Fantasy Football leagues don’t even have kickers on the roster, which I think does a disservice to a player who probably doesn’t get invited to the cool team parties yet can decide the fate of a season in a single moment (like mine). As long as they suit up to take the field, the rest is out of your control. However, is it a suboptimal strategy to relegate your choice of kicker to the final round of the draft? Let’s find out!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-started&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting Started&lt;/h3&gt;
&lt;p&gt;Before loading any data or discussing techniques, we’ll begin by defining our analytical objective. An easy way to get started is by posing a simple question: “How many more points can I expect over a 16-game regular season if I draft the best kicker relative to the worst kicker?” We’ll answer this question in two steps. First, we’ll estimate the &lt;em&gt;True&lt;/em&gt; field goal percentage for each kicker currently active in the NFL (as of 2016), which is analogous to a batting average in baseball or free-throw percentage in basketball. This parameter estimate will be used to compare the skill of one kicker to another. Second, we’ll translate our estimate into actual Fantasy Football points by simulating the outcomes 1000 football seasons for each kicker. Simulation enables us to quantify a realistic point differential between kickers, which is what we (the Fantasy Football team owners) will use to determine if we should try to select the best kicker by drafting in an earlier round.&lt;/p&gt;
&lt;p&gt;With that question in mind, let’s load all pertinent libraries. The data can be downloaded directly from the 🎋 &lt;a href=&#34;https://github.com/thecodeforest&#34;&gt;the codeforest data repo&lt;/a&gt; 🎄. Note the original data comes from Kaggle and can found &lt;a href=&#34;https://www.kaggle.com/kendallgillies/nflstatistics/version/1?select=Career_Stats_Field_Goal_Kickers.csv&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Modeling 
library(gamlss)

# Core packages
library(tidyverse)
library(janitor)

# Visualization 
library(ggplot2)
library(scales)
library(viridis)
library(ggridges)

# Tables
library(gt)

# Global plot theme
theme_set(theme_minimal())

# Code Forest repo
data_url &amp;lt;- &amp;quot;https://raw.githubusercontent.com/thecodeforest/codeforest_datasets/main/fantasy_football_kickers_data/Career_Stats_Field_Goal_Kickers.csv&amp;quot;

# Helper function for visualization
my_plot_theme = function(){
  font_family = &amp;quot;Helvetica&amp;quot;
  font_face = &amp;quot;bold&amp;quot;
  return(theme(
    axis.text.x = element_text(size = 16, face = font_face, family = font_family),
    axis.text.y = element_text(size = 16, face = font_face, family = font_family),
    axis.title.x = element_text(size = 16, face = font_face, family = font_family),
    axis.title.y = element_text(size = 16, face = font_face, family = font_family),
    strip.text.y = element_text(size = 22, face = font_face, family = font_family),
    plot.title = element_text(size = 22, face = font_face, family = font_family),
    
    legend.position = &amp;quot;top&amp;quot;,
    legend.title = element_text(size = 16,
                                face = font_face,
                                family = font_family),
    legend.text = element_text(size = 16,
                               face = font_face,
                               family = font_family),
    legend.key = element_rect(size = 5),
    legend.key.size = unit(1.5, &amp;#39;lines&amp;#39;)
  ))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are several columns we won’t be using so we’ll select only the relevant ones.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats_raw &amp;lt;- read_csv(data_url) %&amp;gt;% 
  clean_names() %&amp;gt;% 
  select(player_id, 
         name, 
         year, 
         games_played, 
         contains(&amp;#39;made&amp;#39;), 
         contains(&amp;#39;attempted&amp;#39;),
         contains(&amp;#39;percentage&amp;#39;),
         -contains(&amp;#39;extra&amp;#39;), 
         -longest_fg_made
         )

glimpse(stats_raw)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1,994
## Columns: 19
## $ player_id                  &amp;lt;chr&amp;gt; &amp;quot;jeffhall/2500970&amp;quot;, &amp;quot;benagajanian/2508255&amp;quot;…
## $ name                       &amp;lt;chr&amp;gt; &amp;quot;Hall, Jeff&amp;quot;, &amp;quot;Agajanian, Ben&amp;quot;, &amp;quot;Agajanian…
## $ year                       &amp;lt;dbl&amp;gt; 2000, 1964, 1962, 1961, 1961, 1960, 1957, …
## $ games_played               &amp;lt;dbl&amp;gt; 3, 3, 6, 3, 3, 14, 12, 10, 12, 12, 10, 12,…
## $ f_gs_made                  &amp;lt;chr&amp;gt; &amp;quot;4&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;5&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;13&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;5&amp;quot;, …
## $ f_gs_made_20_29_yards      &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;…
## $ f_gs_made_30_39_yards      &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;…
## $ f_gs_made_40_49_yards      &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;…
## $ f_gs_made_50_yards         &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;…
## $ f_gs_attempted             &amp;lt;chr&amp;gt; &amp;quot;5&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;14&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;9&amp;quot;, &amp;quot;24&amp;quot;, &amp;quot;18&amp;quot;, &amp;quot;13&amp;quot;…
## $ f_gs_attempted_20_29_yards &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;…
## $ f_gs_attempted_30_39_yards &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;…
## $ f_gs_attempted_40_49_yards &amp;lt;chr&amp;gt; &amp;quot;2&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;…
## $ f_gs_attempted_50_yards    &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;…
## $ fg_percentage              &amp;lt;chr&amp;gt; &amp;quot;80.0&amp;quot;, &amp;quot;50.0&amp;quot;, &amp;quot;35.7&amp;quot;, &amp;quot;50.0&amp;quot;, &amp;quot;33.3&amp;quot;, &amp;quot;5…
## $ fg_percentage_20_29_yards  &amp;lt;chr&amp;gt; &amp;quot;100.0&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--…
## $ fg_percentage_30_39_yards  &amp;lt;chr&amp;gt; &amp;quot;100.0&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--…
## $ fg_percentage_40_49_yards  &amp;lt;chr&amp;gt; &amp;quot;50.0&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;…
## $ fg_percentage_50_yards     &amp;lt;chr&amp;gt; &amp;quot;100.0&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;--…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Like most real-world datasets, this one is a bit messy (e.g., non-values are coded as “–”). I find it helps at the outset of data cleaning to envision what a perfect, pristine dataset should look like once data munging steps are complete. Below is an example of a basic starting point.
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#zpvivrqdou .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#zpvivrqdou .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#zpvivrqdou .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#zpvivrqdou .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#zpvivrqdou .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#zpvivrqdou .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#zpvivrqdou .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#zpvivrqdou .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#zpvivrqdou .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#zpvivrqdou .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#zpvivrqdou .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#zpvivrqdou .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#zpvivrqdou .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#zpvivrqdou .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#zpvivrqdou .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#zpvivrqdou .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#zpvivrqdou .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#zpvivrqdou .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#zpvivrqdou .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#zpvivrqdou .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#zpvivrqdou .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#zpvivrqdou .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#zpvivrqdou .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#zpvivrqdou .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#zpvivrqdou .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#zpvivrqdou .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#zpvivrqdou .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#zpvivrqdou .gt_left {
  text-align: left;
}

#zpvivrqdou .gt_center {
  text-align: center;
}

#zpvivrqdou .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#zpvivrqdou .gt_font_normal {
  font-weight: normal;
}

#zpvivrqdou .gt_font_bold {
  font-weight: bold;
}

#zpvivrqdou .gt_font_italic {
  font-style: italic;
}

#zpvivrqdou .gt_super {
  font-size: 65%;
}

#zpvivrqdou .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;zpvivrqdou&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34; style=&#34;table-layout: fixed;; width: 0px&#34;&gt;
  &lt;colgroup&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
  &lt;/colgroup&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;3&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;strong&gt;Desired Data Format&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;3&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;id&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;n_success&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;n_trials&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;5&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;7&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;3&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;4&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;10&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;5&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;20&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;24&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;6&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;30&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;7&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;60&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;200&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;8&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;9&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;11&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;10&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;24&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;61&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;I used generic column names if you’re interested in adopting the techniques described herein to solve a separate problem. At a basic level, each row represents an individual observation, a count of the number of successes (i.e., count how many field goals are made), and finally the number of trials (i.e., count how many field goals are attempted). If you have this setup, the building blocks are in place to get started.&lt;/p&gt;
&lt;p&gt;However, before going any further, we need to ensure the relationships in the data align with our understanding of the world. One approach is to generate some simple hypotheses that you know to be true. For example, water is wet, the sky is blue, and, in our case, the field goal percentage should decrease as the distance to the goal increases. That is, field goals taken from 50+ yards should be made at a lower rate those taken from 30-35 yards. Let’s verify our hypothesis below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;make_by_dist &amp;lt;-
  stats_raw %&amp;gt;%
  select(starts_with(&amp;quot;fg_percentage_&amp;quot;)) %&amp;gt;%
  mutate_all(as.numeric) %&amp;gt;%
  gather(key = &amp;quot;dist&amp;quot;, value = &amp;quot;fg_pct&amp;quot;) %&amp;gt;%
  mutate(
    dist = str_extract(dist,
                       pattern = &amp;quot;\\d{2}&amp;quot;
                       ),
    dist = if_else(dist == &amp;quot;50&amp;quot;,
                   paste0(dist, &amp;quot;+&amp;quot;),
                   paste0(dist,&amp;quot;-&amp;quot;,as.numeric(dist) + 9)
                   ),
    fg_pct = fg_pct / 100
  ) %&amp;gt;%
  na.omit()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;make_by_dist %&amp;gt;% 
  ggplot(aes(fg_pct, dist, fill = dist)) + 
  geom_density_ridges(
    aes(point_color = dist, 
        point_fill = dist, 
        point_shape = dist),
        alpha = .2, 
        point_alpha = 1, 
        jittered_points = TRUE
    ) + 
  scale_point_color_hue(l = 40) +
  scale_discrete_manual(aesthetics = &amp;quot;point_shape&amp;quot;, 
                        values = c(21, 22, 23, 24)) + 
  scale_x_continuous(labels = scales::percent,
                     breaks = c(0,0.2, 0.4, 0.6, 0.8, 1)
                     ) + 
  scale_fill_viridis_d() + 
  my_plot_theme() + 
  labs(x = &amp;#39;Field Goal Percentage&amp;#39;,
       y = &amp;#39;Distance (Yards)&amp;#39;
       ) + 
    theme(legend.position = &amp;#39;none&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks good! Each point represents the field goal percentage for a player-season-distance combination. As the distance increases, the make rate gradually shifts to left, which is exactly what we’d expect. We’ll do a bit more cleaning below before proceeding.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats_processed &amp;lt;- 
  stats_raw %&amp;gt;%
  mutate(
    name = str_remove(name, &amp;quot;,&amp;quot;),
    first_name = map(name, function(x) str_split(x, &amp;quot; &amp;quot;)[[1]][2]),
    last_name = map(name, function(x) str_split(x, &amp;quot; &amp;quot;)[[1]][1]),
    player_id = str_extract(player_id, &amp;quot;\\d+&amp;quot;)
  ) %&amp;gt;%
  unite(&amp;quot;name&amp;quot;, c(&amp;quot;first_name&amp;quot;, &amp;quot;last_name&amp;quot;), sep = &amp;quot; &amp;quot;) %&amp;gt;%
  mutate_at(vars(matches(&amp;quot;attempted|made&amp;quot;)), as.numeric) %&amp;gt;% 
  replace(., is.na(.), 0) %&amp;gt;% 
  select(player_id, name, year, games_played, contains(&amp;quot;made&amp;quot;), contains(&amp;quot;attempted&amp;quot;)) %&amp;gt;%
  rename(
    fg_made = f_gs_made,
    fg_attempted = f_gs_attempted
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s view the resulting data for one of the best kickers in modern NFL to familiarize ourselves with the format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats_processed %&amp;gt;%
  filter(name == &amp;quot;Justin Tucker&amp;quot;) %&amp;gt;%
  mutate(fg_pct = fg_made / fg_attempted) %&amp;gt;% 
  select(name, year, fg_made, fg_attempted)&lt;/code&gt;&lt;/pre&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#pkjidbziro .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#pkjidbziro .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#pkjidbziro .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#pkjidbziro .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#pkjidbziro .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pkjidbziro .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#pkjidbziro .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#pkjidbziro .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#pkjidbziro .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#pkjidbziro .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#pkjidbziro .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#pkjidbziro .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#pkjidbziro .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#pkjidbziro .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#pkjidbziro .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#pkjidbziro .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#pkjidbziro .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#pkjidbziro .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#pkjidbziro .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#pkjidbziro .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#pkjidbziro .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#pkjidbziro .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#pkjidbziro .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pkjidbziro .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#pkjidbziro .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#pkjidbziro .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#pkjidbziro .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#pkjidbziro .gt_left {
  text-align: left;
}

#pkjidbziro .gt_center {
  text-align: center;
}

#pkjidbziro .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#pkjidbziro .gt_font_normal {
  font-weight: normal;
}

#pkjidbziro .gt_font_bold {
  font-weight: bold;
}

#pkjidbziro .gt_font_italic {
  font-style: italic;
}

#pkjidbziro .gt_super {
  font-size: 65%;
}

#pkjidbziro .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;pkjidbziro&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34; style=&#34;table-layout: fixed;; width: 0px&#34;&gt;
  &lt;colgroup&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
    &lt;col style=&#34;width:155px;&#34;/&gt;
  &lt;/colgroup&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;4&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;&lt;strong&gt;Justin Tucker Stats&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;4&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;name&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;year&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;fg_made&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;fg_attempted&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;Justin Tucker&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2016&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;38&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;39&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;Justin Tucker&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2015&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;33&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;40&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;Justin Tucker&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2014&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;29&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;34&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;Justin Tucker&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2013&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;38&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;41&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;Justin Tucker&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2012&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;30&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;33&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;Just like what we had above! Next, we’ll add a few filters to reduce some of the noise in our data. Any player who has less than 30 field goal attempts and/or has kicked field goals in only one season across their career will be excluded from the analysis. Additionally, we’ll ignore any players with a rookie year before the 1970s. The rationale here is that the NFL made several changes to the location and positioning of the goal during the early 70s, so we want to keep the dynamics of the kicking environment consistent for all players.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;min_attempts &amp;lt;- 30
min_seasons &amp;lt;- 2
min_decade &amp;lt;- 1970

filter_df &amp;lt;- 
  stats_processed %&amp;gt;% 
  group_by(player_id) %&amp;gt;% 
  summarise(n_seasons = n(),
            n_attempts = sum(fg_attempted),
            rookie_decade = min(year) %/% 10 * 10
            ) %&amp;gt;% 
  filter(n_seasons &amp;gt;= min_seasons,
         n_attempts &amp;gt;= min_attempts,
         rookie_decade &amp;gt;= min_decade
         ) %&amp;gt;% 
  select(player_id)

stats_processed &amp;lt;- inner_join(stats_processed, filter_df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we’ll add a few features before aggregating the kicking data from a season level to a career level for each player. I’ll cover the rationale of the features shortly in the estimation and inference section below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_time_stats &amp;lt;- 
  stats_processed %&amp;gt;% 
  group_by(player_id) %&amp;gt;% 
  summarise(
    rookie_decade  = min(year) %/% 10 * 10,
    last_yr_active = max(year)
    ) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  filter(rookie_decade &amp;gt;= min_decade) %&amp;gt;% 
  mutate(status = ifelse(last_yr_active == 2016, &amp;#39;active&amp;#39;, &amp;#39;inactive&amp;#39;))

stats_processed &amp;lt;- inner_join(stats_processed,df_time_stats)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have our time-based features and the last step is to calculate our three key metrics – successes, attempts, and our rate metric.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats_agg &amp;lt;- 
  stats_processed %&amp;gt;% 
  group_by(player_id, name, rookie_decade, status) %&amp;gt;% 
  summarise(fg_made = sum(fg_made),
            fg_attempted = sum(fg_attempted),
            fg_pct = fg_made / fg_attempted
            ) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time to move on to the key focus of this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimation-and-inference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Estimation and Inference&lt;/h3&gt;
&lt;p&gt;Let’s now discuss the logic underlying our estimation method as well as the role of the additional features (Note that some of the code below was inspired by the excellent book &lt;a href=&#34;http://varianceexplained.org/r/empirical-bayes-book/&#34;&gt;Introduction to Empirical Bayes: Examples from Baseball Statistics&lt;/a&gt; by David Robinson). To recap, we are estimating a proportion that captures the relationship between successes and attempts. We can model this outcome with the &lt;code&gt;beta distribution&lt;/code&gt;, which is simply a distribution of probabilities ranging from 0 - 1. In our case, it represents the likelihood of a particular field goal percentage for each player, which will fall somewhere between 0.5 and 0.9 depending on the decade(s) the player was active (more on that in second).&lt;/p&gt;
&lt;p&gt;Below we’ll fit an &lt;em&gt;null model&lt;/em&gt; with no additional parameters when estimating each player’s &lt;code&gt;beta&lt;/code&gt; value. The absence of any inputs means that all players have the same &lt;code&gt;prior&lt;/code&gt;, independent of what decade they played in, whether they’re still active, or how many chances they’ve had to kick a field goal. We’ll then take our prior and update it based on how much information we have about each player, namely the number of field goals they’ve taken and how often they’ve succeeded.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_null &amp;lt;- gamlss(cbind(fg_made, fg_attempted - fg_made) ~ 1,
  family = BB(mu.link = &amp;quot;identity&amp;quot;),
  data = stats_agg
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GAMLSS-RS iteration 1: Global Deviance = 936.6917 
## GAMLSS-RS iteration 2: Global Deviance = 836.9846 
## GAMLSS-RS iteration 3: Global Deviance = 828.0258 
## GAMLSS-RS iteration 4: Global Deviance = 827.9528 
## GAMLSS-RS iteration 5: Global Deviance = 827.9526&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats_agg_est &amp;lt;- 
  stats_agg %&amp;gt;% 
   mutate(
    mu = fitted(fit_null, &amp;quot;mu&amp;quot;), 
    sigma = fitted(fit_null, &amp;quot;sigma&amp;quot;), 
    alpha0 = mu / sigma, 
    beta0 = (1 - mu) / sigma,
    alpha1 = alpha0 + fg_made,
    beta1 = beta0 + fg_attempted - fg_made,
    estimate = alpha1 / (alpha1 + beta1),
    raw = fg_made / fg_attempted,
    low = qbeta(.025, alpha1, beta1),
    high = qbeta(.975, alpha1, beta1)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s plot out the estimate for all active players.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats_agg_est %&amp;gt;%
  mutate(name = paste0(name, &amp;quot;: &amp;quot;, fg_made, &amp;quot;|&amp;quot;, fg_attempted),
         name = fct_reorder(name, estimate)
         ) %&amp;gt;%
  filter(status == &amp;quot;active&amp;quot;) %&amp;gt;%
  ggplot(aes(name, estimate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = low, ymax = high)) +
  coord_flip() +
  geom_point(aes(name, raw), color = &amp;quot;red&amp;quot;, size = 3, alpha = 0.6) +
  scale_y_continuous(labels = scales::percent_format()) + 
  my_plot_theme() + 
  labs(x = NULL,
       y = &amp;#39;Field Goal Percentage&amp;#39;,
       title = &amp;#39;Estimated field goal percentage amongst active NFL kickers&amp;#39;,
       subtitle = &amp;#39;Black dot represents estimate while red dot is actual. Note the bias in our estimates.&amp;#39;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s talk through this figure by comparing the field goal percentage estimates for Adam Vinatieri, who has made 530 of 629 fields goals throughout his career, to Chris Boswell, who has made 50 of 57 field goals. While Vinatieri has a lower actual make rate than Boswell (84.2% vs. 87.7%), we consider him to be a better field goal kicker. The seemingly incongruent finding is based on the fact that we have more evidence for Vinatieri (629 FG attempts vs. 57 FG attempts) than Boswell. It’s like saying, “Chris Boswell is good kicker, maybe better than Vinatieri, but we don’t have enough evidence (yet) to believe he is that much better than an average kicker, a number represented by our prior”. Indeed, if we also consider the width of the credible intervals surrounding these two players, Adam Vinatieri’s interval is considerably smaller than Chris Boswell’s interval.&lt;/p&gt;
&lt;p&gt;While this is a good way to gain an intuition for what’s happening under the hood, we see an immediate problem – all of our estimates are biased! The actual field goal percentage is above every single estimate. Luckily, there is a solution: we can create conditional estimates of our prior. One way to do this is to create features that explain variability between our players. For example, &lt;a href=&#34;https://fivethirtyeight.com/features/kickers-are-forever/&#34;&gt;field goal percentages have improved dramatically over the past 50 years&lt;/a&gt;. Let’s consider our own data and map out this pattern from the 1970s to the 2010s.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats_agg %&amp;gt;%
  mutate(rookie_decade = as.factor(rookie_decade)) %&amp;gt;%
  ggplot(aes(rookie_decade, fg_pct, color = rookie_decade)) +
  geom_boxplot() +
  geom_jitter() +
  scale_y_continuous(labels = scales::percent_format()) +
  my_plot_theme() +
  scale_color_viridis_d() + 
  theme(legend.position = &amp;quot;none&amp;quot;) +
  labs(
    x = &amp;quot;Decade&amp;quot;,
    y = &amp;quot;Field Goal Percentage&amp;quot;,
    title = &amp;#39;Kicker performance has improved over time&amp;#39;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;1152&#34; /&gt;
The best kicker in 1970s has a lower field goal percentage than the worst kicker in the 2010s. Including the decade of a kicker’s rookie season allows us to create a more informed prior. Thus, if we use the median field goal percentage of all kickers who debuted as rookies in 2010+, our best guess would be about 84%, whereas a kicker who debuted in the 1970s would be somewhere around 64%. This explains why the estimates from our null model were biased.&lt;/p&gt;
&lt;p&gt;The second factor to consider is the number of field goal attempts per player, because better players have more opportunities to kick field goals. This makes intuitive sense and is captured in the following plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats_agg %&amp;gt;%
  ggplot(aes(log2(fg_attempted), fg_pct)) +
  geom_point(size = 3) +
  geom_smooth(span = 1) +
  scale_y_continuous(labels = scales::percent_format()) +
  my_plot_theme() +
  labs(
    x = &amp;quot;Log2(Total Attempts)&amp;quot;,
    y = &amp;quot;Field Goal percentage&amp;quot;,
    title = &amp;quot;Better kickers have more opportunities&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Below we’ll use the same model except this time we’ll account for the number of field goal attempts and a player’s rookie decade.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_complete &amp;lt;- 
  gamlss(cbind(fg_made, fg_attempted - fg_made) ~ log2(fg_attempted) + rookie_decade,
  family = BB(mu.link = &amp;quot;identity&amp;quot;),
  data = stats_agg
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GAMLSS-RS iteration 1: Global Deviance = 918.3071 
## GAMLSS-RS iteration 2: Global Deviance = 714.8471 
## GAMLSS-RS iteration 3: Global Deviance = 668.3708 
## GAMLSS-RS iteration 4: Global Deviance = 668.1839 
## GAMLSS-RS iteration 5: Global Deviance = 668.1838&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;1152&#34; /&gt;
Much better! Our estimates do not exhibit the same degree of bias as before. Moreover, the width of our credible intervals shrank across all players. This makes sense, given that we can now condition our prior estimates on inputs that explain variability in the field goal percentage. While there are other factors that might improve our model (e.g., did a player’s team have their home games in a dome?), this is a good starting point for answering our original question.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;from-parameters-to-points&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;From Parameters to Points&lt;/h3&gt;
&lt;p&gt;We have a model that does a reasonable job of estimating a kicker’s field goal percentage. Now we need to translate that into an estimate of fantasy points. This will take a few steps, but I’ll outline each in turn. First, we need to estimate the average worth (in fantasy points) of each successful field goal. Typically, field goals less-than 40 yards are worth 3 points, 40 - 49 yards are worth 4 points, and 50 or more yards are worth 5 points. We’ll use the 2016 season to come up with a global average. While we could technically account for distances of each player (e.g., some kickers are excellent at a longer distances, others not so much), this approach will give us a “good-enough” answer. Second, we’ll estimate the average number of field goal attempts per season. This can vary widely from one season to the next for a given kicker, as it is contingent upon the offense getting within kicking range. Again, we’ll keep it simple and just average the number of attempts across all players from the 2016 season.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Average points per FG
pts_per_fg &amp;lt;- 
  stats_processed %&amp;gt;% 
  filter(year == 2016) %&amp;gt;% 
  mutate(pt_3_fgs = (f_gs_made_20_29_yards + f_gs_made_30_39_yards) * 3,
         pt_4_fgs = f_gs_made_40_49_yards * 4,
         pt_5_fgs = f_gs_made_50_yards * 5,
         tot_pts = pt_3_fgs + pt_4_fgs + pt_5_fgs
  )

pts_per_fg &amp;lt;- round(sum(pts_per_fg$tot_pts) / sum(pts_per_fg$fg_made), 1)

# Average number of attempts
attempts_per_season &amp;lt;- 
  stats_processed %&amp;gt;% 
  filter(year == 2016) %&amp;gt;% 
  pull(fg_attempted) %&amp;gt;% 
  mean() %&amp;gt;% 
  round()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here comes the fun part. Below we’ll simulate 1000 seasons for each player by randomly generating 1000 values of &lt;code&gt;beta&lt;/code&gt;. This value is based on the posterior estimates, &lt;code&gt;alpha1&lt;/code&gt; and &lt;code&gt;beta1&lt;/code&gt;, produced by our model. The estimates will vary from one simulation to next, though most values will fall somewhere between 0.75 and 0.9. Better players like Justin Tucker will be near the high end of that range while player like Graham Gano will be near the lower end. We’ll then take each estimate and plug it into the &lt;code&gt;binomial distribution&lt;/code&gt; below. Recall that the &lt;code&gt;binomial distribution&lt;/code&gt; is defined by a single parameter, which represents the probability of success. This is exactly what our estimate of &lt;code&gt;beta&lt;/code&gt; represents! Given that all active players had an average of 27 FG attempts in 2016, each of the 1000 simulations will consist of 27 trials (or &lt;code&gt;attempts_per_season&lt;/code&gt;) each with a slightly different probability of success (how likely they are to make a field goal on a given attempt). We’ll lean on the &lt;code&gt;purrr&lt;/code&gt; package to vectorize these operations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2018)
n_seasons &amp;lt;- 1000

est_active &amp;lt;- 
  stats_agg_est %&amp;gt;% 
  filter(status == &amp;#39;active&amp;#39;)

est_make_pct &amp;lt;- map2(est_active %&amp;gt;% pull(alpha1),
                     est_active %&amp;gt;% pull(beta1), 
                     function(x, y) rbeta(n_seasons, x, y)
                     )
est_outcomes &amp;lt;- map(est_make_pct, 
                    function(x) rbinom(n = n_seasons, 
                                       size = attempts_per_season,
                                       prob = x
                                       )
                    )
names(est_outcomes) &amp;lt;- est_active$name&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So much data! Below we’ll plot the distribution of total points accumulated for each player across the 1000 simulated seasons. We’ll create quantiles as a way to see how much overlap there is between players.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pt_simulation &amp;lt;- 
  est_outcomes %&amp;gt;% 
  tbl_df() %&amp;gt;% 
  gather() %&amp;gt;% 
  transmute(name = key,
            season_pts = value * pts_per_fg
            ) %&amp;gt;% 
  group_by(name) %&amp;gt;% 
  mutate(avg_pts = mean(season_pts)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(name = fct_reorder(name, avg_pts))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `tbl_df()` is deprecated as of dplyr 1.0.0.
## Please use `tibble::as_tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pt_simulation %&amp;gt;% 
  ggplot(aes(season_pts, y = name, fill = factor(..quantile..))) + 
  stat_density_ridges(
    geom = &amp;quot;density_ridges_gradient&amp;quot;,
    calc_ecdf = TRUE,
    quantiles = 4,
    quantile_lines = TRUE,
    bandwidth = 2
  ) +
  scale_fill_viridis(discrete = TRUE, name = &amp;quot;Point Quartile&amp;quot;, alpha = 0.5) +
  my_plot_theme() + 
  scale_x_continuous(breaks = pretty_breaks(n = 7)) + 
  labs(x = &amp;#39;Total Points Per Simulated Season&amp;#39;,
       y = NULL,
       title = &amp;quot;The best kicker is not much better than the worst kicker&amp;quot;,
       subtitle = &amp;#39;Drafing any kicker is fine&amp;#39;
       ) + 
  theme(legend.position = &amp;#39;none&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wait! We went all this way for you to tell me that the status quo is probably right? Yes, I did. But we still haven’t quantified how much better or worse drafting the best or worst kicker is in terms of fantasy points. A simple way is to count the number of seasons where Justin Tucker (the best kicker) scored more points than Andrew Franks (the worst kicker).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;jt_pts &amp;lt;- 
  pt_simulation %&amp;gt;% 
  filter(name == &amp;#39;Justin Tucker&amp;#39;) %&amp;gt;% 
  pull(season_pts) 

af_pts &amp;lt;- 
pt_simulation %&amp;gt;% 
  filter(name == &amp;#39;Andrew Franks&amp;#39;) %&amp;gt;% 
  pull(season_pts)

pct_greater &amp;lt;- sum(jt_pts &amp;gt; af_pts) / n_seasons
print(str_glue(&amp;#39;PCT greater: {pct_greater * 100}%&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## PCT greater: 77.5%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Turns out that approximately 77 of every 100 seasons Justin Tucker outscores Andrew Franks. Let’s go one step further and quantify the actual difference.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data.frame(pt_diff = jt_pts - af_pts), aes(pt_diff)) + 
  geom_histogram(fill = &amp;#39;gray&amp;#39;, color = &amp;#39;black&amp;#39;, bins = 10) + 
  scale_x_continuous(breaks = pretty_breaks(n = 15)) + 
  labs(x = &amp;#39;Point Difference over Entire Season&amp;#39;) + 
  theme_minimal() + 
  geom_vline(xintercept = quantile(jt_pts - af_pts, .05), lty = 2) + 
  geom_vline(xintercept = quantile(jt_pts - af_pts, .5), lty = 2, color = &amp;#39;red&amp;#39;, size = 2) + 
  geom_vline(xintercept = quantile(jt_pts - af_pts, .95), lty = 2) + 
  my_plot_theme() + 
  labs(x = &amp;#39;Point Difference&amp;#39;,
       y = &amp;#39;Count&amp;#39;,
       title = &amp;#39;The best kicker should score about 10 more points per season compared to the worst&amp;#39;,
       subtitle = &amp;#39;Estimate based on 27 FG attempts per season with each FG worth 3.5 points&amp;#39;
       )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2019-08-29-fantasy-football-kickers/fantasy_football_kickers_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;1152&#34; /&gt;
If we spread this estimate out across 16 regular-season games, it comes out to less than a single point per game.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Needless to say, pick your kicker last in Fantasy Football! All kickers in modern-day NFL are really good, so save those late-round picks for positions other than a kicker. Cheers!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>http://example.org/publication/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://example.org/publication/preprint/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>http://example.org/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>http://example.org/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://example.org/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>http://example.org/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Choosing a Fantasy Football Quarterback</title>
      <link>http://example.org/post/2017-09-10-choosing-ff-qb/choosing_fantasy_qb/</link>
      <pubDate>Sun, 10 Sep 2017 21:13:14 -0500</pubDate>
      <guid>http://example.org/post/2017-09-10-choosing-ff-qb/choosing_fantasy_qb/</guid>
      <description>


&lt;p&gt;&lt;img src=&#34;http://example.org/post/2017-09-10-choosing-ff-qb/choosing_fantasy_qb_files/mariota.jpg&#34; width=&#34;700&#34; height=&#34;400&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;p&gt;Understanding a new concept is all about connecting it with something you already know. I don’t know much, but I do know Fantasy Football. Thus, when I come across new concepts, I often think to myself, “How can I use this information to beat my friend Steve in Fantasy Football”? This very question was the impetus for putting these words and figures together in a post, which will introduce the idea of using the Beta Distribution to determine your weekly starter. I’ll explain this approach in the context of my 2015 Fantasy Football season.&lt;/p&gt;
&lt;p&gt;At the outset of that season, I drafted two quarterbacks: Joe Flacco and Marcus Mariota (it was a rough draft). Flacco had been in the NFL for a few years, while Mariota was still a rookie yet to play a game. I was also considering a separate rookie, Jameis Winston, who was available to pick up anytime during the season off the waiver wire. Throughout the season, I was faced with the following questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Who do I make the starting QB?&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If one QB is performing poorly, when is the right time to make the switch (e.g., Flacco -&amp;gt; Mariota; Flacco -&amp;gt; Winston; Mariota -&amp;gt; Winston)?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This question is faced by NFL coaches and fantasy owners alike. If your QB has a few bad weeks, should you continue with them into the next week, replace them with the 2nd string QB, or sign a free agent to your team mid-season?&lt;/p&gt;
&lt;p&gt;Before getting into the technical details, let’s first define what “Success” looks like for a Fantasy Football QB. Success can be defined in one word: Consistency. A QB that throws three touchdowns (TDs) every game for the first six games of the season (18 total) is better than a QB who throws five TDs for the first three games and then one TD during the next three games, despite having thrown the same number of TDs. Simply put - you want consistent, reliable performance every week. It doesn’t matter if you win by one point or 50 points – a win is a win. Thus, I evaluate my QB’s performance on the following criteria: A “Successful” performance is defined as &lt;strong&gt;3 or more touchdowns AND/OR 300 or more yards&lt;/strong&gt; for a given week. Touchdowns and passing yards are the two primary sources of QB fantasy points, and a +3TD|300yard weekly statline should cement a QB amongst that week’s top performers. Failing to meet either of these criteria was defined as an “Unsuccessful” performance. Note that this label could also factor in interceptions, pass completions, and fumble, but we’ll keep it simple and just focus on passing yards and passing touchdowns.&lt;/p&gt;
&lt;p&gt;Having defined the evaluation criteria, the data generating process was modeled via the beta distribution. Recall that the beta distribution defines a distribution of probabilities, and we’re interested in the probability of our QB having a Successful week. There are several years of performance history on Joe Flacco, so we can provide a reasonably informed estimate of his weekly probabilty for achieving success (i.e., our prior). In contrast, there is no NFL game history on Mariota or Winston, so we’ll assign each a uniform or uninformative prior. Our estimate of the Success parameter for Winston and Mariota will change rapidly as we acquire in-season data because our posterior is determined entirely from the data. We could create a more informed-–and stronger-–prior by assigning Mariota and Winston the historic first-year league average for all rookie QBs entering the NFL but we’ll keep it simple. A uniform prior means that all probabilities from 0-1 are equally likely.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collecting-qb-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Collecting QB Data&lt;/h3&gt;
&lt;p&gt;We’ll use the &lt;code&gt;nflgame&lt;/code&gt; python package to gather QB data. We’ll pull 2013-2014 weekly performance data for Joe Flacco to calculate our prior, as well as the 2015 data for all three players. During the season we’ll update our priors to determine which QB we should play for a given week. That is, as we acquire results over the season, updates will be made to obtain a better, more reliable estimate of the “success” parameter for each QB.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import nflgame
import pandas as pd

game_years = range(2013, 2016)
game_weeks = range(1, 17)
qbs = (&amp;quot;Joe Flacco&amp;quot;, 
       &amp;quot;Marcus Mariota&amp;quot;,
       &amp;quot;Jameis Winston&amp;quot;)
       
def get_passing_data(year, week, players, qbs):
    qb_list = list()
    for p in players.passing():
        player = &amp;quot; &amp;quot;.join(str(p.player).split(&amp;quot; &amp;quot;)[:2]) 
        if player in qbs:
            qb_list.append([year, week, player, p.passing_tds, p.passing_yds])
    return qb_list
    
quarterback_data = pd.DataFrame()
for year in game_years:
    print &amp;quot;Retrieving Player Data for {year}&amp;quot;.format(year = year)
    for week in game_weeks:
        games = nflgame.games(year, week)
        players = nflgame.combine_game_stats(games)
        temp_qb_stats = get_passing_data(year, week, players, qbs)
        quarterback_data = quarterback_data.append(pd.DataFrame(temp_qb_stats))
        
quarterback_data.columns = [&amp;quot;year&amp;quot;, &amp;quot;week&amp;quot;, &amp;quot;player&amp;quot;, &amp;quot;touchdowns&amp;quot;, &amp;quot;passing_yds&amp;quot;]
quarterback_data.to_csv(&amp;quot;quarterback_data.csv&amp;quot;, index = False)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>http://example.org/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://example.org/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>http://example.org/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>http://example.org/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>http://example.org/publication/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>http://example.org/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>http://example.org/publication/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>http://example.org/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://example.org/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://example.org/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title>Time to Run with AWS</title>
      <link>http://example.org/post/2021-04-20-running-alert-aws-lambda/running_alert_aws_lambda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://example.org/post/2021-04-20-running-alert-aws-lambda/running_alert_aws_lambda/</guid>
      <description>


&lt;div id=&#34;overview&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;p&gt;As a runner, I’ve always enjoyed the pursuit of pacing faster today relative to yesterday. With the advent of apps like &lt;a href=&#34;https://www.strava.com/&#34;&gt;Strava&lt;/a&gt; that track your performance (among many other metrics), it’s easy to measure if you are running faster over time and, perhaps more importantly, which factors affect your run pace. Indeed, based on my historical running data, I’ve noticed two factors that moderate my run times: time of day and weather. My fastest runs usually happen between 12 PM - 7 PM, and slower runs occurred with high winds, cold weather (less than 30°F ), hot weather (greater than 90°F), or rain (being wet makes me miserable). On these “bad weather” days, I’d prefer to run inside on the treadmill and wait until more optimal running conditions.&lt;/p&gt;
&lt;p&gt;With these criteria in mind, I would begin most mornings by deciding if it was an “inside” or “outside” running day by executing the following mental steps:&lt;/p&gt;
&lt;p&gt;☁️ Log on to weather.com at 7AM&lt;br /&gt;
☁️ Check the hourly forecast between 12PM and 5PM&lt;br /&gt;
☁️ Check the temperature, wind-speed, and chance of precipitation&lt;br /&gt;
☁️ Make a “Yes” or “No” decision to run outside based on the forecast&lt;/p&gt;
&lt;p&gt;While it isn’t a huge inconvenience to repeat these steps each day, it required a few minutes of the morning. Perhaps more importantly, though, it was yet another decision that needed attention. I make lots of decisions in a day, and each decision requires thought and energy. Thus, if I could automate one of those decisions by creating a “rules engine,” it would save me the time and cognition required to plan my daily run.&lt;/p&gt;
&lt;p&gt;The journey of automating this process is what inspired the following post, which will cover a few key concepts, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scheduling a workflow using AWS Event Bridge&lt;/li&gt;
&lt;li&gt;Building Lambda functions&lt;/li&gt;
&lt;li&gt;Sending emails via AWS SES&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These concepts can be generalized to any reoccurring process. Perhaps it’s a daily forecast that planners use to manage a store’s inventory. Or maybe it’s a marketing email sent to new customers after making their first purchase. Extracting data from a database/API, applying some business logic, and then socializing the results through an Email is a standard analytics workflow. Read on to learn more about how I leveraged this approach to identify the best times to run each day, save myself a few minutes, and remove one more decision from my day.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;be-the-algorithm&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Be The Algorithm&lt;/h3&gt;
&lt;p&gt;Before diving into the solution, I wanted to quickly discuss a technique I’ve found helpful when automating a decision-making process. Before writing code or building queries, it’s good to step through the process manually that you are trying to automate. That is, you want to assume the role of the computer or algorithm. Repeating the steps above each day made it clear how I would automate the decision-making process by identifying:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The information I needed to make a decision&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;The timing and frequency of the decision&lt;/li&gt;
&lt;li&gt;The values of the criteria that would lead to an “inside” or “outside” run decision&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You could easily sub in a machine learning model to discover the rules, but the overall process flow will be essentially unchanged. Keep this in mind next time you go to create a process that automates a decision.&lt;br /&gt;
In the next section, we’ll cover the technical specifics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;architecture-overview&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Architecture Overview&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/architecture_flow.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;&lt;br /&gt;
No post on AWS would be complete without a diagram outlining how data flows through our system. Accordingly, the figure above depicts the order of operations and each service’s role in our decision workflow. Each service is described in greater detail below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Event Bridge&lt;/strong&gt; - this is our scheduler. Each day at Noon PST, Amazon Event Bridge initiates the first Lambda function (TimeToRun).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Lambda (TimeToRun)&lt;/strong&gt; - TimeToRun connects to the OpenWeather API, extracts weather forecasts for my latitude and longitude, and formats the resulting data. The forecasts are then saved to an S3 bucket.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Lambda (SendRunningEmail)&lt;/strong&gt; - SendRunningEmail is triggered by any action in the S3 bucket containing the hourly weather forecasts. In this case, when a new object lands in the bucket, the Lambda function automatically starts and retrieves the data from the S3 bucket.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Amazon SES&lt;/strong&gt; - While this service is part of the SendRunningEmail Lambda, I separated it since it’s such a helpful service. Sending emails through Python can be tricky, and I’ve found the approach using AWS SES to be much easier. You import the service, define the message contents, add a bit of HTML (to make it look pretty, of course), and send the message to a set of desired email addresses. It’s that simple.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Personal Gmail&lt;/strong&gt; - this is where the resulting message lands, alerting me if it is an “inside” or “outside” running day.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the following sections, we’ll cover the two Lambda functions that comprise this workflow. We’ll also cover a few “gotchas” that come up frequently when working with Lambda for the first time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-1-timetorun&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 1: TimeToRun&lt;/h3&gt;
&lt;p&gt;The first part will cover the data collection process, which briefly entails:&lt;br /&gt;
1. Scheduling&lt;br /&gt;
2. Extracting hourly forecasts from OpenWeather API&lt;br /&gt;
3. Saving the forecasts to an S3 bucket&lt;/p&gt;
&lt;p&gt;We’ll use EventBridge for scheduling, which you can see in the diagram on the left below.
&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/eventbridge.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;
To connect Lambda with EventBridge, you add a trigger and then indicate how frequently you want it to execute. The desired cadence for the hourly weather forecasts was every weekday at 7 PM GMT (or noon PST), expressed via Cron below.
&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/cron_expression.png&#34; width=&#34;200&#34; height=&#34;200&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now that we’ve scheduled our Lambda function, the next step is to add logic that collects the forecasts and saves them to S3.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import os
import sys
from typing import List
import json
from datetime import datetime
import logging

import pytz
import requests
import boto3

S3_BUCKET = &amp;quot;running-weather-data&amp;quot;

logger = logging.getLogger()
logger.setLevel(logging.INFO)


def retrieve_weather_data(units_of_measure: str) -&amp;gt; dict:
    api_key = os.environ[&amp;quot;WEATHER_API_KEY&amp;quot;]
    lat = os.environ[&amp;quot;LOCATION_LATITUDE&amp;quot;]
    lon = os.environ[&amp;quot;LOCATION_LONGITUDE&amp;quot;]
    base_url = &amp;quot;https://api.openweathermap.org/data/2.5/onecall?&amp;quot;
    url = f&amp;quot;{base_url}lat={lat}&amp;amp;lon={lon}&amp;amp;appid={api_key}&amp;amp;units={units_of_measure}&amp;quot;
    response = requests.get(url)
    weather_data = json.loads(response.text)
    return weather_data


def parse_weather_data(weather_hour: dict) -&amp;gt; dict:
    hour = datetime.fromtimestamp(
        weather_hour[&amp;quot;dt&amp;quot;], pytz.timezone(&amp;quot;America/Los_Angeles&amp;quot;)
    ).hour
    temp = weather_hour[&amp;quot;temp&amp;quot;]
    wind_speed = weather_hour[&amp;quot;wind_speed&amp;quot;]
    weather_status = weather_hour[&amp;quot;weather&amp;quot;][0]
    status = weather_status[&amp;quot;main&amp;quot;]
    return {&amp;quot;hour&amp;quot;: hour, &amp;quot;temp&amp;quot;: temp, &amp;quot;wind_speed&amp;quot;: wind_speed, &amp;quot;status&amp;quot;: status}


def is_today_weather(weather_hour: dict, timezone: str = &amp;quot;America/Los_Angeles&amp;quot;) -&amp;gt; bool:
    weather_fmt = &amp;quot;%Y-%m-%d&amp;quot;
    today_dt = datetime.now().strftime(weather_fmt)
    weather_dt = datetime.fromtimestamp(weather_hour[&amp;quot;dt&amp;quot;], pytz.timezone(timezone))
    if weather_dt.strftime(weather_fmt) == today_dt:
        return True
    else:
        return False


def _generate_s3_path() -&amp;gt; str:
    year, month, day = datetime.now().strftime(&amp;quot;%Y-%m-%d&amp;quot;).split(&amp;quot;-&amp;quot;)
    s3_path = f&amp;quot;data/{year}-{month}-{day}-running-times.json&amp;quot;
    return s3_path


def save_json_to_s3(json_data: dict, s3_bucket: str) -&amp;gt; None:
    s3 = boto3.resource(&amp;quot;s3&amp;quot;)
    response = s3.Object(s3_bucket, _generate_s3_path()).put(
        Body=(bytes(json.dumps(json_data).encode(&amp;quot;UTF-8&amp;quot;)))
    )
    if response.get(&amp;quot;HTTPStatusCode&amp;quot;) == 200:
        print(f&amp;quot;Data successfully landed&amp;quot;)


def lambda_handler(event, context):
    try:
        # retrieve weather forecast from OpenWeatherAPI
        weather_data = retrieve_weather_data(units_of_measure=&amp;quot;imperial&amp;quot;)
        # extract hourly forecast
        hourly_data = weather_data[&amp;quot;hourly&amp;quot;]
        # filter to only today&amp;#39;s forecast
        today_weather_bool = [is_today_weather(x) for x in hourly_data if x]
        # extract fields relevant to deciding if run outside
        hourly_data = [parse_weather_data(x) for x in hourly_data]
        # filter to today&amp;#39;s hourly data
        today_hourly_data = [
            today_weather
            for (today_weather, is_today) in zip(hourly_data, today_weather_bool)
            if is_today
        ]
        # convert all data to dictionary
        hourly_data_dict = {&amp;quot;weather_data&amp;quot;: today_hourly_data}
        # save hourly weather data to S3 Bucket as .json
        save_json_to_s3(json_data=json.dumps(hourly_data_dict), s3_bucket=S3_BUCKET)
        return {&amp;quot;statusCode&amp;quot;: 200, &amp;quot;body&amp;quot;: json.dumps(hourly_data_dict)}
    except Exception as exp:
        exception_type, exception_value, exception_traceback = sys.exc_info()
        err_msg = json.dumps(
            {&amp;quot;errorType&amp;quot;: exception_type.__name__, &amp;quot;errorMessage&amp;quot;: str(exception_value)}
        )
        logger.error(err_msg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This entire block of code is what get’s triggered daily, landing a single &lt;em&gt;.json&lt;/em&gt; file in the desired S3 Bucket. While this looks straightforward, it’s not as simple as copy-pasting your code and hitting play. Like most things in the AWS ecosystem, getting everything to work takes a few tries. The subsections below highlight areas that are potential sources of confusion when starting with Lambda.&lt;/p&gt;
&lt;div id=&#34;configuring-environment-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Configuring Environment Variables&lt;/h4&gt;
&lt;p&gt;Environmental variables store sensitive information, such as API keys, passwords, or other private values. In this case, I’ve stored the OpenWeather API key and Latitude/Longitude of where I want the daily forecasts. The image below depicts how to add these variables via the console.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/environment_variables.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;&lt;br /&gt;
And this is where these variables are accessed in the Lambda code.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def retrieve_weather_data(units_of_measure: str) -&amp;gt; dict:
    api_key = os.environ[&amp;quot;WEATHER_API_KEY&amp;quot;]
    lat = os.environ[&amp;quot;LOCATION_LATITUDE&amp;quot;]
    lon = os.environ[&amp;quot;LOCATION_LONGITUDE&amp;quot;]
    base_url = &amp;quot;https://api.openweathermap.org/data/2.5/onecall?&amp;quot;
    url = f&amp;quot;{base_url}lat={lat}&amp;amp;lon={lon}&amp;amp;appid={api_key}&amp;amp;units={units_of_measure}&amp;quot;
    response = requests.get(url)
    weather_data = json.loads(response.text)
    return weather_data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that this approach to managing keys and constants is sufficient for smaller projects and prototypes. However, for larger projects where you are collaborating with other developers and stakeholders, configuration data will likely be stored in a way that allows for versioning and tracking.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-layers&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Adding Layers&lt;/h4&gt;
&lt;p&gt;A layer is a .zip file that includes additional code or data. If you noticed in the &lt;code&gt;retrieve_weather_data&lt;/code&gt; function, we use the &lt;em&gt;requests&lt;/em&gt; package to access the OpenWeather API. &lt;em&gt;Requests&lt;/em&gt; is not part of the Python Standard Library, so we must include it as part of a layer (there is no way to &lt;code&gt;pip install requests&lt;/code&gt; or any other third-party libraries). While a full explanation of adding a layer is beyond the scope of this post, &lt;a href=&#34;https://towardsdatascience.com/how-to-install-python-packages-for-aws-lambda-layer-74e193c76a91&#34;&gt;the following article&lt;/a&gt; nicely summarizes how to incorporate third-party libraries on Lambda.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-permissions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Adding Permissions&lt;/h4&gt;
&lt;p&gt;Any time you set up a service through AWS, the default is to have minimal permissions in place. Among other activities, permissions allow your lambda function to interact with other AWS services. For example, the &lt;strong&gt;TimeToRun&lt;/strong&gt; Lambda function writes the weather forecasts to an S3 bucket. The ability to interact with S3 is not setup by default, so you’ll have to attach a policy. Below I’ve enabled &lt;em&gt;AmazonS3FullAccess&lt;/em&gt;, which allows access to S3. You’ll need to do the same for the second lambda function as well.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/s3_permissions_access.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;
If you ever receive an error message like “…is not authorized to perform…”, it usually can be solved by updating the permissions for a given service.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;run-time-limit&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Run Time Limit&lt;/h4&gt;
&lt;p&gt;A second default setting that might not be immediately obvious is the standard run-time limit. This setting indicates how long AWS will let a Lambda run before terminating. The default is set to three seconds. Depending on the processing time, I’ll usually increase the limit to 30 seconds and then gradually go down or up from there. The image below indicates where you can adjust the run-time or memory for more compute-heavy tasks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/run_time_limit.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;
If you’ve successfully implemented all of the steps above, you should receive something that looks like this when testing the function:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/test_success.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This response indicates that everything ran smoothly and you are ready to move on to Part 2!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2-sendrunningemail-lambda&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part 2: SendRunningEmail Lambda&lt;/h3&gt;
&lt;p&gt;The second part of this post covers the data formatting and transmission process in four steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Extract data from S3&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Determine if “inside” or “outside” running day&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Format the decision, so it looks nice&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Send the decision to the desired email address(es)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import sys
import boto3
import json
import logging
from datetime import datetime
from typing import List

S3_BUCKET = &amp;quot;&amp;lt;weather-data-bucket-name&amp;gt;&amp;quot;
SENDER = &amp;quot;&amp;lt;sender-email-address&amp;gt;&amp;quot;
RECIPIENT = &amp;quot;&amp;lt;recipient-email-addresses&amp;gt;&amp;quot;
AWS_REGION = &amp;quot;us-west-2&amp;quot;
SUBJECT = &amp;quot;Best Times to Run Today&amp;quot;
CHARSET = &amp;quot;UTF-8&amp;quot;
RUNNING_CONDS = {
    &amp;quot;hour&amp;quot;: {&amp;quot;min_hour&amp;quot;: 13, &amp;quot;max_hour&amp;quot;: 19},
    &amp;quot;status&amp;quot;: [&amp;quot;Rain&amp;quot;, &amp;quot;Snow&amp;quot;, &amp;quot;Smoke&amp;quot;],
    &amp;quot;wind_speed&amp;quot;: {&amp;quot;min_speed&amp;quot;: 0, &amp;quot;max_speed&amp;quot;: 30},
    &amp;quot;temp&amp;quot;: {&amp;quot;min_temp&amp;quot;: 30, &amp;quot;max_temp&amp;quot;: 90},
}

logger = logging.getLogger()
logger.setLevel(logging.INFO)


def find_most_recent_data_path(s3_bucket: str) -&amp;gt; str:
    today_dt = datetime.now().strftime(&amp;quot;%Y-%m-%d&amp;quot;)
    s3 = boto3.resource(&amp;quot;s3&amp;quot;)
    bucket = s3.Bucket(s3_bucket)
    existing_data = [
        x.key
        for x in bucket.objects.all()
        if str(x.key).startswith(&amp;quot;data&amp;quot;) and str(x.key).endswith(&amp;quot;-running-times.json&amp;quot;)
    ]
    most_recent_dt = max(
        [x.split(&amp;quot;/&amp;quot;)[-1].replace(&amp;quot;-running-times.json&amp;quot;, &amp;quot;&amp;quot;) for x in existing_data]
    )
    assert most_recent_dt == today_dt, &amp;quot;No Data Found for Today&amp;#39;s Date&amp;quot;
    s3_key = [x for x in existing_data if most_recent_dt in x][0]
    return s3_key


def read_json_from_s3(s3_bucket: str, s3_key: str) -&amp;gt; str:
    s3 = boto3.resource(&amp;quot;s3&amp;quot;)
    obj = s3.Object(s3_bucket, s3_key)
    file_content = obj.get()[&amp;quot;Body&amp;quot;].read().decode(&amp;quot;utf-8&amp;quot;)
    json_content = json.loads(file_content)
    return json_content


def _convert_to_12hr_format(hr: int) -&amp;gt; str:
    return datetime.strptime(str(hr), &amp;quot;%H&amp;quot;).strftime(&amp;quot;%I:%M %p&amp;quot;).strip(&amp;quot;0&amp;quot;)


def format_run_times(run_times: List[dict]) -&amp;gt; str:
    if run_times:
        hour_fmt = [
            f&amp;quot;&amp;lt;b&amp;gt;{_convert_to_12hr_format(x.get(&amp;#39;hour&amp;#39;))}:&amp;lt;/b&amp;gt;&amp;quot; for x in run_times
        ]
        temp_fmt = [f&amp;quot;{round(x.get(&amp;#39;temp&amp;#39;))}F with&amp;quot; for x in run_times]
        wind_speed_fmt = [
            f&amp;quot;wind at {round(x.get(&amp;#39;wind_speed&amp;#39;))} mph&amp;quot; for x in run_times
        ]
        status_fmt = [f&amp;quot;and {x.get(&amp;#39;status&amp;#39;).lower()}&amp;quot; for x in run_times]
        fmt_msg = zip(hour_fmt, temp_fmt, wind_speed_fmt, status_fmt)
        fmt_msg_list = [&amp;quot; &amp;quot;.join(x) for x in fmt_msg]
        return fmt_msg_list
    else:
        return [&amp;quot;No Times to Run Today!&amp;quot;]


def is_time_for_run(weather_hour: dict) -&amp;gt; bool:
    is_time = (
        RUNNING_CONDS[&amp;quot;hour&amp;quot;][&amp;quot;min_hour&amp;quot;]
        &amp;lt;= weather_hour[&amp;quot;hour&amp;quot;]
        &amp;lt;= RUNNING_CONDS[&amp;quot;hour&amp;quot;][&amp;quot;max_hour&amp;quot;]
    )
    is_temp = (
        RUNNING_CONDS[&amp;quot;temp&amp;quot;][&amp;quot;min_temp&amp;quot;]
        &amp;lt;= weather_hour[&amp;quot;temp&amp;quot;]
        &amp;lt;= RUNNING_CONDS[&amp;quot;temp&amp;quot;][&amp;quot;max_temp&amp;quot;]
    )
    is_wind = (
        RUNNING_CONDS[&amp;quot;wind_speed&amp;quot;][&amp;quot;min_speed&amp;quot;]
        &amp;lt;= weather_hour[&amp;quot;wind_speed&amp;quot;]
        &amp;lt;= RUNNING_CONDS[&amp;quot;wind_speed&amp;quot;][&amp;quot;max_speed&amp;quot;]
    )
    is_status = weather_hour[&amp;quot;status&amp;quot;] not in RUNNING_CONDS[&amp;quot;status&amp;quot;]
    if all([is_time, is_temp, is_wind, is_status]):
        return True
    else:
        return False


def lambda_handler(event, context):
    # generate s3 key for most recent weather data
    running_data_path = find_most_recent_data_path(s3_bucket=S3_BUCKET)
    # read as str
    hourly_weather_data = read_json_from_s3(
        s3_bucket=S3_BUCKET, s3_key=running_data_path
    )
    # convert to dict and extract weather data
    hourly_data_dict = eval(hourly_weather_data)[&amp;quot;weather_data&amp;quot;]

    # True or False filter based on hour, temperature, windspeed criteria
    run_time_bool = [is_time_for_run(x) for x in hourly_data_dict]

    # applies weather criteria and filters only to hours where critera are met
    run_times = [
        time
        for (time, time_to_run) in zip(hourly_data_dict, run_time_bool)
        if time_to_run
    ]
    running_msg_lst = format_run_times(run_times)
    running_msg_str = &amp;quot;&amp;lt;p&amp;gt;&amp;quot; + &amp;quot;&amp;lt;br/&amp;gt;&amp;quot;.join(running_msg_lst) + &amp;quot;&amp;lt;/p&amp;gt;&amp;quot;
    running_msg = f&amp;quot;&amp;quot;&amp;quot;&amp;lt;html&amp;gt;
                        &amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;
                        &amp;lt;body&amp;gt;
                        &amp;lt;h1&amp;gt;Best Times to Run&amp;lt;/h1&amp;gt;
                        {running_msg_str}
                        &amp;lt;/body&amp;gt;
                        &amp;lt;/html&amp;gt;
                        &amp;quot;&amp;quot;&amp;quot;
    try:
        client = boto3.client(&amp;quot;ses&amp;quot;, region_name=AWS_REGION)
        response = client.send_email(
            Destination={
                &amp;quot;ToAddresses&amp;quot;: [
                    RECIPIENT,
                ]
            },
            Message={
                &amp;quot;Body&amp;quot;: {
                    &amp;quot;Html&amp;quot;: {
                        &amp;quot;Charset&amp;quot;: CHARSET,
                        &amp;quot;Data&amp;quot;: running_msg,
                    },
                },
                &amp;quot;Subject&amp;quot;: {
                    &amp;quot;Charset&amp;quot;: CHARSET,
                    &amp;quot;Data&amp;quot;: SUBJECT,
                },
            },
            Source=SENDER,
        )
    except Exception as exp:
        exception_type, exception_value, exception_traceback = sys.exc_info()
        err_msg = json.dumps(
            {&amp;quot;errorType&amp;quot;: exception_type.__name__, &amp;quot;errorMessage&amp;quot;: str(exception_value)}
        )
        logger.error(err_msg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most of the logic is concerned with accessing and formatting the data we collected in the first part. However, this is where we determine an inside or outside run. The two sections highlighted below are responsible for making this decision.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;RUNNING_CONDS = {
    &amp;quot;hour&amp;quot;: {&amp;quot;min_hour&amp;quot;: 13, &amp;quot;max_hour&amp;quot;: 19},
    &amp;quot;status&amp;quot;: [&amp;quot;Rain&amp;quot;, &amp;quot;Snow&amp;quot;, &amp;quot;Smoke&amp;quot;],
    &amp;quot;wind_speed&amp;quot;: {&amp;quot;min_speed&amp;quot;: 0, &amp;quot;max_speed&amp;quot;: 30},
    &amp;quot;temp&amp;quot;: {&amp;quot;min_temp&amp;quot;: 30, &amp;quot;max_temp&amp;quot;: 90},
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are all of the criteria - time, status (I probably don’t want to run if there’s a 🔥wildfire🔥), wind speed, and temperature - and their limits used in making the running decision. The &lt;code&gt;is_time_for_run&lt;/code&gt; function ensures that the forecast data satisfies all four conditions.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def is_time_for_run(weather_hour: dict) -&amp;gt; bool:
    is_time = (
        RUNNING_CONDS[&amp;quot;hour&amp;quot;][&amp;quot;min_hour&amp;quot;]
        &amp;lt;= weather_hour[&amp;quot;hour&amp;quot;]
        &amp;lt;= RUNNING_CONDS[&amp;quot;hour&amp;quot;][&amp;quot;max_hour&amp;quot;]
    )
    is_temp = (
        RUNNING_CONDS[&amp;quot;temp&amp;quot;][&amp;quot;min_temp&amp;quot;]
        &amp;lt;= weather_hour[&amp;quot;temp&amp;quot;]
        &amp;lt;= RUNNING_CONDS[&amp;quot;temp&amp;quot;][&amp;quot;max_temp&amp;quot;]
    )
    is_wind = (
        RUNNING_CONDS[&amp;quot;wind_speed&amp;quot;][&amp;quot;min_speed&amp;quot;]
        &amp;lt;= weather_hour[&amp;quot;wind_speed&amp;quot;]
        &amp;lt;= RUNNING_CONDS[&amp;quot;wind_speed&amp;quot;][&amp;quot;max_speed&amp;quot;]
    )
    is_status = weather_hour[&amp;quot;status&amp;quot;] not in RUNNING_CONDS[&amp;quot;status&amp;quot;]
    if all([is_time, is_temp, is_wind, is_status]):
        return True
    else:
        return False&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll receive a message (like the one below) in my inbox every weekday at Noon when these conditions are met.
&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/running_email.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;
Otherwise, I’ll receive the message below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://example.org/post/2021-04-20-running-alert-aws-lambda/images/no_run_message.png&#34; width=&#34;700&#34; height=&#34;600&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Overall, it looks like a solid day for a run. The one thing to note is that 3 PM and 4 PM do not have any information. The absence of data at these times indicates that at least one of the criteria was not met. Indeed, the local weather forecast showed rain for those times, so they were automatically filtered out in the message, leaving only times that met all four criteria. Portland, Oregon (Where I Live) is a rainy place, and this sort of granular information is beneficial for those days where you get a brief window of dryness to go run.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parting-thoughts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Parting Thoughts&lt;/h3&gt;
&lt;p&gt;I hope this was a helpful introduction to setting up and running a basic Lambda workflow. It is a useful service, and I’ve found numerous applications in my day-to-day life beyond just helping me plan my daily run. Please feel free to comment below if you have any thoughts or questions. Until next time, happy coding!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
